[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aaron Olson",
    "section": "",
    "text": "Hi, I‚Äôm Aaron üëã\nI am a data analyst with a background in the R Statistical Programming Language. This site is where I post my various data projects and document my experiences learning to code.\nMy areas of subject-matter expertise include U.S. Census data and population statistics. I am also an avid sports data enthusiast.\nSend me an email if you want to collaborate or subscribe to receive updates on my email list.\n\n \n\nDisclaimer: Everything on this site comes from my own mind and is not associated with any employer or organization that I am currently or previously attached to"
  },
  {
    "objectID": "posts/2024-10-21-hello-world/index.html",
    "href": "posts/2024-10-21-hello-world/index.html",
    "title": "Hello, World",
    "section": "",
    "text": "Hey there! üëã\nWelcome to my blog. Special thanks to Samantha Csik‚Äôs wonderful guide on setting up a blog on a Quarto website.\nDon‚Äôt worry, I come in peace."
  },
  {
    "objectID": "posts/2024-10-21-hello-world/index.html#viewing-source-code-on-this-site",
    "href": "posts/2024-10-21-hello-world/index.html#viewing-source-code-on-this-site",
    "title": "Hello, World",
    "section": "üîé Viewing source code on this site",
    "text": "üîé Viewing source code on this site\nData analyses in the blog posts on this site are usually conducted with the R coding language. To view the code that generates the analysis, click the ‚Äú&gt; Code‚Äù dropdown button above each chunk.\nThere is also a button on the top right corner of every post with code-folding enabled to globally expand or collapse all code chunks.\n\nCode Chunk Example\nFor example, the code that loads the iris dataset and generates the plot below can be expanded or collapsed by the ‚Äú&gt; Code‚Äù dropdown button.\n\n\nCode\nboxplot(Sepal.Length~Species,\n        data=iris,\n        main='Sepal Length by Species',\n        xlab='Species',\n        ylab='Sepal Length',\n        col='steelblue',\n        border='black')\n\n\n\n\n\nA boxplot of the iris dataset\n\n\n\n\nIt‚Äôs a useful feature of Quarto that allows for documents to be consumed easily by both technical and non-technical readers.\nHappy reading üòÅ"
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html",
    "href": "posts/2024-11-22-tidycensus-guide/index.html",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "There are many ways to access U.S. Census Bureau data. For years, I used data.census.gov to query data, download spreadsheets, and clean them in Excel. This process was tedious, inefficient, and quite frankly sucked.\nEverything changed when I learned R and discovered the tidycensus package, created by Kyle Walker. Tidycensus uses the Census API to pull data directly into R in a tidy format, making analysis and visualization straightforward.\nThis post is a quick reference for getting started with tidycensus. Even if you‚Äôre new to R, this can be a great motivator to learn. I‚Äôll by demonstrate pulling income data for Indiana‚Äôs 92 counties from the ACS data. For a more comprehensive guide, check out Walker‚Äôs book on the package.\n\n\nIn order to use tidycensus, you must first obtain an API key from the Census Bureau. You can request a key here and should receive it via email shortly.\nOnce you have an API key, you can install the package and set your key. My key will remain invisible in this post, but you should run the following code and fill in the placeholder with your own key if you are following along.\nNote, I am also using the tidyverse package, which is my go-to for data wrangling and visualization.\n\nlibrary(\"tidycensus\")\nlibrary(\"tidyverse\")\n\ncensus_api_key(\"YOUR KEY HERE\", install = TRUE, overwrite = TRUE)\n\n\n\n\nA huge benefit right off the bat is the ability to view all available variables in the ACS data. The code below will pull a list of all variables in the detailed ACS tables for the 2022 5-Year sample. A more in-depth guide to accessing the right variables for your project can be found here.\n\n# load all variables for the 2022 ACS 5-Year sample\nv22 &lt;- load_variables(2022, \"acs5\", cache = TRUE)\n\n# show the first 10 rows of the variables dataframe\nhead(v22)\n\n\n  \n\n\n\nI typically like to open up the varibles dataframe in RStudio‚Äôs viewer pane for easier searching. Here, I‚Äôve searched for ‚Äúmedian household income‚Äù and a ton of options popped up. It can be tricky to pick the right one. My best advice is to scroll over to the right and look at the ‚Äúconcept‚Äù column to see more details.\n\nVariable B19013_001 has a concept description of ‚ÄúMedian Household Income in the Past 12 Months (in 2022 Inflation-Adjusted Dollars)‚Äù, which sounds good.\nAn extra check that you have the right data is to pull that variable for the nation as a whole and compare to what you see on data.census.gov. Below, I‚Äôve gone to the census website and searched for the ‚ÄúB19013‚Äù table and filtered for the 2022 5-Year ACS. The median household income for the U.S. in that year was $75,149\n\nLet‚Äôs see what tidycensus says! The code below is a simple ACS pull for the variable we‚Äôve identified.\n\n# pull the median household income for the U.S. in 2022 (5-Year Sample)\nus_income &lt;- get_acs(\n  geography = \"us\", \n  variables = \"B19013_001\", \n  year = 2022, \n  survey = \"acs5\")\n\n# print the results\nus_income\n\n\n  \n\n\n\nBingo. The numbers match. Now that we know we have identified the variable we want, let‚Äôs pull the data for Indiana‚Äôs 92 counties.\n\n\n\nUsing the same get_acs function, we can pull the median household income for Indiana‚Äôs counties in 2022. Notice in the code below that we are now using ‚Äúcounty‚Äù for the geography argument and ‚ÄúIN‚Äù for the state argument.\nIf the state argument is left blank, the function will pull data for counties nationwide, which can be useful but not necessary for this example.\n\n# pull the median household income for Indiana's 92 counties in 2022 (5-Year Sample)\nin_income &lt;- get_acs(\n  geography = \"county\", \n  variables = \"B19013_001\", \n  state = \"IN\", \n  survey = \"acs5\", \n  year = 2022)\n\n# show the 10 highest income counties\nin_income %&gt;% arrange(desc(estimate))\n\n\n  \n\n\n\nWe can see that Hamilton County had the highest median household income in Indiana in 2022, followed by Boone and Hendricks counties.\n\n\n\nAt this point, we can do all sorts of things to visualize the data. Perhaps you‚Äôd like to see a histogram of household income.\n\n# create a histogram of Indiana's county-level median household income\nin_income %&gt;% \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 20, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Median Household Income Distribution\",\n       subtitle = \"Indiana Counties\",\n       caption = \"2022 5-Year ACS\",\n       x = \"Median Household Income\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHamilton and Boone counties are clear outliers in the data when it comes to income. The median clusters around $60K.\n\n\n\nOr maybe you‚Äôd like to see the data on a map. In order to prep the data for mapping, all we need to do is re-run the get_acs function with the geometry = TRUE argument. This will pull the spatial data for the counties in Indiana.\nNow that we have the spatial data, we can map the median household income for Indiana‚Äôs counties.\n\n# make a map\nin_income_geo %&gt;%\n  ggplot(aes(fill = estimate)) +\n  geom_sf(color = \"white\") +\n  scale_fill_viridis_c() +\n  labs(title = \"Median Household Income\",\n       subtitle = \"Indiana Counties\",\n       caption = \"Source: American Community Survey\") +\n  theme_void()\n\n\n\n\n\n\n\n\nIf you‚Äôve tried to make maps in one of various softwares before, you should see the incredible value of this workflow. With just a few lines of code, I‚Äôve generated a clean map.\nBut there‚Äôs more!\n\n\nUsing the mapview package, this map can be quickly made interactive. Again, if you‚Äôve mapped before, the efficiency here is truly remarkable.\n\n# make an interactive map\nlibrary(\"mapview\")\n\nin_income_geo %&gt;%\n  mapview::mapview(zcol = \"estimate\", layer.name = \"Median Household Income($))\")\n\n\n\n\n\nThat‚Äôs it. A few more simple lines of code and you have an interactive map.\n\n\n\n\n\n\nIn addition to grabbing an ACS estimate for a single variable for a single year, tidycensus can also pull data over time. Below, I‚Äôve pulled the median household income for Marion County, Indiana from 2012 to 2022.\nThis requires writing a loop using map_dfr from the purrr package. The map_dfr function is helpful to combine the results of each iteration into a single dataframe.\nDon‚Äôt be scared. Once you have the loop written once you can modify and reuse again and again.\n\n# pull median household income for Marion County, Indiana from 2012 to 2022\n# NOTE: 2020 single year ACS estimates were not released due to the pandemic\n\n# specify years\nyears &lt;- c(2012:2019, 2021:2022)\nnames(years) &lt;- years\n\n# run the loop\nincome_by_year &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"county\",\n    variables = \"B19013_001\",\n    state = \"IN\",\n    county = \"Marion\",\n    survey = \"acs1\",\n    year = .x\n  )\n}, .id = \"year\")\n\n# make a line graph of the data\nincome_by_year %&gt;%\n  ggplot(aes(x = year, y = estimate, group = 1)) +\n  geom_line(color = \"skyblue\") +\n  labs(title = \"Median Household Income Over Time\",\n       subtitle = \"Marion County, Indiana\",\n       caption = \"Source: American Community Survey\",\n       x = \"Year\",\n       y = \"Median Household Income ($)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nNOTE: median household income is not adjusted for inflation\n\n\n\nTidycensus supports geographic subsetting, meaning that you can pull data for a certain geography that is contained within a larger geography. For example, you could get median household income for all census tracts within Marion County.\nThat example is below, with the geometry argument set to ‚ÄúTRUE‚Äù required for mapping.\nNow let‚Äôs map the results!\n\n# make a map\nmarion_income %&gt;%\n  ggplot(aes(fill = estimate)) +\n  geom_sf(color = \"white\") +\n  scale_fill_viridis_c() +\n  labs(title = \"Median Household Income\",\n       subtitle = \"Marion County, Indiana\",\n       caption = \"Source: American Community Survey\") +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nTypically when working through geographic analysis with Census data, you will want to have access to more than just one variable. Yet again, tidycensus makes this easy.\nBelow I have pulled the median household income and the percentage of households with broadband internet access for census tracts in Marion County, Indiana in 2022.\nNotice the argument output = \"wide\" in the get_acs function. This argument allows for variables to be split out into multiple columns, making the next step easier.\n\n# pull median household income and percentage of households with broadband internet access for Marion county, Indiana in 2022\n\nmarion_vars &lt;- c(\"B19013_001\", \"S2801_C02_014\")\n\nmarion_vars_data &lt;- get_acs(\n  geography = \"tract\",\n  county = \"Marion\",\n  state = \"IN\",\n  variables = marion_vars,\n  survey = \"acs5\",\n  output = \"wide\",\n  year = 2022\n)\n\nWith both of this variables pulled, perhaps you‚Äôd like to see the geographic relationship between the two. That can easily be done with a scatter plot.\n\n# make a scatter plot of the two variables\nmarion_vars_data %&gt;%\n  ggplot(aes(x = B19013_001E, y = S2801_C02_014E)) +\n  geom_point(color = \"skyblue\") +\n  labs(title = \"Income vs. Broadband Access\",\n       subtitle = \"Marion County, Indiana\",\n       caption = \"Source: American Community Survey\",\n       x = \"Median Household Income ($)\",\n       y = \"Households with Broadband (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere‚Äôs so much more you can do. But hopefully this has piqued your interest.\n\n\n\n\n\nTidycensus documentation\nKyle Walker‚Äôs Tidycensus book\nTidyverse package documentation\nMapview package documentation"
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html#package-installation-and-api-key",
    "href": "posts/2024-11-22-tidycensus-guide/index.html#package-installation-and-api-key",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "In order to use tidycensus, you must first obtain an API key from the Census Bureau. You can request a key here and should receive it via email shortly.\nOnce you have an API key, you can install the package and set your key. My key will remain invisible in this post, but you should run the following code and fill in the placeholder with your own key if you are following along.\nNote, I am also using the tidyverse package, which is my go-to for data wrangling and visualization.\n\nlibrary(\"tidycensus\")\nlibrary(\"tidyverse\")\n\ncensus_api_key(\"YOUR KEY HERE\", install = TRUE, overwrite = TRUE)"
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html#view-acs-variables",
    "href": "posts/2024-11-22-tidycensus-guide/index.html#view-acs-variables",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "A huge benefit right off the bat is the ability to view all available variables in the ACS data. The code below will pull a list of all variables in the detailed ACS tables for the 2022 5-Year sample. A more in-depth guide to accessing the right variables for your project can be found here.\n\n# load all variables for the 2022 ACS 5-Year sample\nv22 &lt;- load_variables(2022, \"acs5\", cache = TRUE)\n\n# show the first 10 rows of the variables dataframe\nhead(v22)\n\n\n  \n\n\n\nI typically like to open up the varibles dataframe in RStudio‚Äôs viewer pane for easier searching. Here, I‚Äôve searched for ‚Äúmedian household income‚Äù and a ton of options popped up. It can be tricky to pick the right one. My best advice is to scroll over to the right and look at the ‚Äúconcept‚Äù column to see more details.\n\nVariable B19013_001 has a concept description of ‚ÄúMedian Household Income in the Past 12 Months (in 2022 Inflation-Adjusted Dollars)‚Äù, which sounds good.\nAn extra check that you have the right data is to pull that variable for the nation as a whole and compare to what you see on data.census.gov. Below, I‚Äôve gone to the census website and searched for the ‚ÄúB19013‚Äù table and filtered for the 2022 5-Year ACS. The median household income for the U.S. in that year was $75,149\n\nLet‚Äôs see what tidycensus says! The code below is a simple ACS pull for the variable we‚Äôve identified.\n\n# pull the median household income for the U.S. in 2022 (5-Year Sample)\nus_income &lt;- get_acs(\n  geography = \"us\", \n  variables = \"B19013_001\", \n  year = 2022, \n  survey = \"acs5\")\n\n# print the results\nus_income\n\n\n  \n\n\n\nBingo. The numbers match. Now that we know we have identified the variable we want, let‚Äôs pull the data for Indiana‚Äôs 92 counties."
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html#pulling-indianas-county-level-data",
    "href": "posts/2024-11-22-tidycensus-guide/index.html#pulling-indianas-county-level-data",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "Using the same get_acs function, we can pull the median household income for Indiana‚Äôs counties in 2022. Notice in the code below that we are now using ‚Äúcounty‚Äù for the geography argument and ‚ÄúIN‚Äù for the state argument.\nIf the state argument is left blank, the function will pull data for counties nationwide, which can be useful but not necessary for this example.\n\n# pull the median household income for Indiana's 92 counties in 2022 (5-Year Sample)\nin_income &lt;- get_acs(\n  geography = \"county\", \n  variables = \"B19013_001\", \n  state = \"IN\", \n  survey = \"acs5\", \n  year = 2022)\n\n# show the 10 highest income counties\nin_income %&gt;% arrange(desc(estimate))\n\n\n  \n\n\n\nWe can see that Hamilton County had the highest median household income in Indiana in 2022, followed by Boone and Hendricks counties."
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html#visualize-the-data",
    "href": "posts/2024-11-22-tidycensus-guide/index.html#visualize-the-data",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "At this point, we can do all sorts of things to visualize the data. Perhaps you‚Äôd like to see a histogram of household income.\n\n# create a histogram of Indiana's county-level median household income\nin_income %&gt;% \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 20, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Median Household Income Distribution\",\n       subtitle = \"Indiana Counties\",\n       caption = \"2022 5-Year ACS\",\n       x = \"Median Household Income\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHamilton and Boone counties are clear outliers in the data when it comes to income. The median clusters around $60K."
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html#mapping-the-data",
    "href": "posts/2024-11-22-tidycensus-guide/index.html#mapping-the-data",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "Or maybe you‚Äôd like to see the data on a map. In order to prep the data for mapping, all we need to do is re-run the get_acs function with the geometry = TRUE argument. This will pull the spatial data for the counties in Indiana.\nNow that we have the spatial data, we can map the median household income for Indiana‚Äôs counties.\n\n# make a map\nin_income_geo %&gt;%\n  ggplot(aes(fill = estimate)) +\n  geom_sf(color = \"white\") +\n  scale_fill_viridis_c() +\n  labs(title = \"Median Household Income\",\n       subtitle = \"Indiana Counties\",\n       caption = \"Source: American Community Survey\") +\n  theme_void()\n\n\n\n\n\n\n\n\nIf you‚Äôve tried to make maps in one of various softwares before, you should see the incredible value of this workflow. With just a few lines of code, I‚Äôve generated a clean map.\nBut there‚Äôs more!\n\n\nUsing the mapview package, this map can be quickly made interactive. Again, if you‚Äôve mapped before, the efficiency here is truly remarkable.\n\n# make an interactive map\nlibrary(\"mapview\")\n\nin_income_geo %&gt;%\n  mapview::mapview(zcol = \"estimate\", layer.name = \"Median Household Income($))\")\n\n\n\n\n\nThat‚Äôs it. A few more simple lines of code and you have an interactive map."
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html#other-tidycensus-capabilities",
    "href": "posts/2024-11-22-tidycensus-guide/index.html#other-tidycensus-capabilities",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "In addition to grabbing an ACS estimate for a single variable for a single year, tidycensus can also pull data over time. Below, I‚Äôve pulled the median household income for Marion County, Indiana from 2012 to 2022.\nThis requires writing a loop using map_dfr from the purrr package. The map_dfr function is helpful to combine the results of each iteration into a single dataframe.\nDon‚Äôt be scared. Once you have the loop written once you can modify and reuse again and again.\n\n# pull median household income for Marion County, Indiana from 2012 to 2022\n# NOTE: 2020 single year ACS estimates were not released due to the pandemic\n\n# specify years\nyears &lt;- c(2012:2019, 2021:2022)\nnames(years) &lt;- years\n\n# run the loop\nincome_by_year &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"county\",\n    variables = \"B19013_001\",\n    state = \"IN\",\n    county = \"Marion\",\n    survey = \"acs1\",\n    year = .x\n  )\n}, .id = \"year\")\n\n# make a line graph of the data\nincome_by_year %&gt;%\n  ggplot(aes(x = year, y = estimate, group = 1)) +\n  geom_line(color = \"skyblue\") +\n  labs(title = \"Median Household Income Over Time\",\n       subtitle = \"Marion County, Indiana\",\n       caption = \"Source: American Community Survey\",\n       x = \"Year\",\n       y = \"Median Household Income ($)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nNOTE: median household income is not adjusted for inflation\n\n\n\nTidycensus supports geographic subsetting, meaning that you can pull data for a certain geography that is contained within a larger geography. For example, you could get median household income for all census tracts within Marion County.\nThat example is below, with the geometry argument set to ‚ÄúTRUE‚Äù required for mapping.\nNow let‚Äôs map the results!\n\n# make a map\nmarion_income %&gt;%\n  ggplot(aes(fill = estimate)) +\n  geom_sf(color = \"white\") +\n  scale_fill_viridis_c() +\n  labs(title = \"Median Household Income\",\n       subtitle = \"Marion County, Indiana\",\n       caption = \"Source: American Community Survey\") +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nTypically when working through geographic analysis with Census data, you will want to have access to more than just one variable. Yet again, tidycensus makes this easy.\nBelow I have pulled the median household income and the percentage of households with broadband internet access for census tracts in Marion County, Indiana in 2022.\nNotice the argument output = \"wide\" in the get_acs function. This argument allows for variables to be split out into multiple columns, making the next step easier.\n\n# pull median household income and percentage of households with broadband internet access for Marion county, Indiana in 2022\n\nmarion_vars &lt;- c(\"B19013_001\", \"S2801_C02_014\")\n\nmarion_vars_data &lt;- get_acs(\n  geography = \"tract\",\n  county = \"Marion\",\n  state = \"IN\",\n  variables = marion_vars,\n  survey = \"acs5\",\n  output = \"wide\",\n  year = 2022\n)\n\nWith both of this variables pulled, perhaps you‚Äôd like to see the geographic relationship between the two. That can easily be done with a scatter plot.\n\n# make a scatter plot of the two variables\nmarion_vars_data %&gt;%\n  ggplot(aes(x = B19013_001E, y = S2801_C02_014E)) +\n  geom_point(color = \"skyblue\") +\n  labs(title = \"Income vs. Broadband Access\",\n       subtitle = \"Marion County, Indiana\",\n       caption = \"Source: American Community Survey\",\n       x = \"Median Household Income ($)\",\n       y = \"Households with Broadband (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere‚Äôs so much more you can do. But hopefully this has piqued your interest."
  },
  {
    "objectID": "posts/2024-11-22-tidycensus-guide/index.html#additional-resources",
    "href": "posts/2024-11-22-tidycensus-guide/index.html#additional-resources",
    "title": "My personal tidycensus guide",
    "section": "",
    "text": "Tidycensus documentation\nKyle Walker‚Äôs Tidycensus book\nTidyverse package documentation\nMapview package documentation"
  },
  {
    "objectID": "posts/2024-12-14-kokomo-annexation/index.html",
    "href": "posts/2024-12-14-kokomo-annexation/index.html",
    "title": "Annexation Station",
    "section": "",
    "text": "Analyzing population growth over time is a common task in demographic analysis. It can be more complex than it seems, particularly at municipal level where city borders can change quite frequently.\nFortunately, R has a series of packages that can help navigate these challenges. This post details how I approach boundary changes in population analysis, using tidycensus, sf and tigris analyzing Kokomo, Indiana as an example.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe analysis in this post uses the tidycensus R package heavily. To learn more about how to set up and use that package, check out my blog post on it here. To view the code behind the analysis, click the dropdowns throughout the post."
  },
  {
    "objectID": "posts/2024-12-14-kokomo-annexation/index.html#introduction",
    "href": "posts/2024-12-14-kokomo-annexation/index.html#introduction",
    "title": "Annexation Station",
    "section": "",
    "text": "Analyzing population growth over time is a common task in demographic analysis. It can be more complex than it seems, particularly at municipal level where city borders can change quite frequently.\nFortunately, R has a series of packages that can help navigate these challenges. This post details how I approach boundary changes in population analysis, using tidycensus, sf and tigris analyzing Kokomo, Indiana as an example.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe analysis in this post uses the tidycensus R package heavily. To learn more about how to set up and use that package, check out my blog post on it here. To view the code behind the analysis, click the dropdowns throughout the post."
  },
  {
    "objectID": "posts/2024-12-14-kokomo-annexation/index.html#kokomos-population-growth",
    "href": "posts/2024-12-14-kokomo-annexation/index.html#kokomos-population-growth",
    "title": "Annexation Station",
    "section": "Kokomo‚Äôs Population Growth",
    "text": "Kokomo‚Äôs Population Growth\nAccording to the most recent decennial Census, Kokomo, Indiana‚Äôs population grew from around 45K in 2010 to over 59K in 2020. That seems significant and worth investigating, especially for a small city whose population had hovered between 44K and 47K since the 1960‚Äôs.\nLet‚Äôs turn to tidycensus.\n\n\nLoad packages and set up API key\nlibrary(\"tidycensus\")\nlibrary(\"tidyverse\")\nlibrary('hrbrthemes') # to make the plots pretty :)\nlibrary(\"sf\")\nlibrary(\"tigris\")\n\ncensus_api_key(Sys.getenv(\"TIDYCENSUS_KEY\"), install = TRUE, overwrite = TRUE)\n\n\nFigure¬†1 shows the significant increase in the city‚Äôs population between 2010 and 2020. The most logical follow-up is to see whether there is a jump in any particular year, or if the change was more gradual.\n\n\nMake a plot of Kokomo‚Äôs population\n# Get population of Kokomo, Indiana in 2000 using get_decennial\npop_2000 &lt;- get_decennial(geography = \"place\", \n                          variables = \"PCT012001\", \n                          state = \"IN\", \n                          year = 2000) %&gt;%\n  filter(\n    NAME == 'Kokomo city, Indiana'\n  )\n\n# Get population of Kokomo, Indiana in 2010 using get_decennial\npop_2010 &lt;- get_decennial(geography = \"place\", \n                          variables = \"P001001\", \n                          state = \"IN\", \n                          year = 2010)  %&gt;%\n  filter(\n    NAME == 'Kokomo city, Indiana'\n  )\n\n\n# Get population of Kokomo, Indiana in 2020 using get_decennial\npop_2020 &lt;- get_decennial(geography = \"place\", \n                          variables = \"P1_001N\", \n                          state = \"IN\", \n                          year = 2020) %&gt;%\n  filter(\n    NAME == 'Kokomo city, Indiana'\n  )\n\n\n# Combine the three data frames into one\nkokomo_pop_data &lt;- bind_rows(pop_2000, pop_2010, pop_2020)\n\n# add a column for the year\nkokomo_pop_data$year &lt;- c(2000, 2010, 2020)\n\n\n# Plot the population of Kokomo over time in a bar chart \nggplot(kokomo_pop_data, aes(x = year, y = value)) +\n  geom_bar(stat = \"identity\", fill = 'dodgerblue') +\n  labs(title = \"Population of Kokomo, Indiana\",\n       subtitle = \"2000, 2010, and 2020 Decennial Census\",\n       x = \"Year\",\n       y = \"Population\") +\n  theme_ipsum() +\n  theme(axis.text.x = element_text(hjust = 1)) +\n  scale_y_continuous(labels = scales::comma, limits = c(0, 62000)) +\n  geom_text(aes(label = scales::comma(value), y = value), vjust = -0.5)\n\n\n\n\n\n\n\n\nFigure¬†1: Population of Kokomo, Indiana, 2000-2020. Decennial Census.\n\n\n\n\n\nThe year-over-year change in population is shown in Figure¬†2. No doubt about it, 2012 is an outlier. The population increased by over 8,000 people in one year, compared to less than 1,300 in every other observation in this data set.\n\n\n\n\n\n\nNote\n\n\n\n\n\nACS population estimates (particular the 5-Year sample) like the ones below aren‚Äôt the most precise population estimates put out by the Census Bureau, they work well enough to show general trends. The 1-Year sample is not available for Kokomo, as it only covers geographies with a population of 65,000 or greater.\n\n\n\n\n\nMake a plot of Kokomo‚Äôs population change over time\n# get annual population estimates for Kokomo\nyears &lt;- c(2010:2022)\nnames(years) &lt;- years\n\nkokomo_by_year &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"place\",\n    variables = \"B01001_001\",\n    state = \"IN\",\n    survey = \"acs5\",\n    year = .x\n  )\n}, .id = \"year\") %&gt;%\n  filter(\n    NAME == 'Kokomo city, Indiana'\n  )\n\n# calculate year over year change in population as a new column\nkokomo_by_year &lt;- kokomo_by_year %&gt;%\n  mutate(\n    pop_change = estimate - lag(estimate),\n    pop_change_pct = (estimate - lag(estimate)) / lag(estimate) * 100\n  )\n\n\n# plot a line chart of the pop_change\nggplot(kokomo_by_year, aes(x = year, y = pop_change, group = 1)) +\n  geom_line(color = 'dodgerblue') +\n  geom_point(color = 'dodgerblue') +\n  labs(title = \"Year over Year Population Change\",\n       subtitle = \"Kokomo, Indiana\",\n       x = \"Year\",\n       y = \"Population Change\") +\n  theme_ipsum() +\n  scale_y_continuous(labels = scales::comma, limits = c(-300, 9000)) +\n  geom_text(aes(label = scales::comma(pop_change), y = pop_change), vjust = -0.5) +\n  scale_x_discrete(breaks = seq(2010, 2022, 2))\n\n\n\n\n\n\n\n\nFigure¬†2: Annual Population Change in Kokomo, Indiana, 2010-2020. ACS."
  },
  {
    "objectID": "posts/2024-12-14-kokomo-annexation/index.html#investigating-city-limit-changes",
    "href": "posts/2024-12-14-kokomo-annexation/index.html#investigating-city-limit-changes",
    "title": "Annexation Station",
    "section": "Investigating City Limit Changes",
    "text": "Investigating City Limit Changes\nBased on the data so far, it appears Kokomo‚Äôs boundaries may have changed around 2012, resulting in annexation of new land and a population increase. To confirm this, I used the tigris package to map the city‚Äôs boundaries over time. The map below shows Kokomo‚Äôs city limits each year from 2014 through 2020 layered on top of one another.\nWhen I attempted to include years before 2014, the tigris package told me that the boundaries were not available for those years. I will address that by importing shapefiles downloaded from the Census website for those specific years later in the post.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere are certainly more elegant ways to write the code below, but in the spirit of the ‚ÄúMake it Work. Make it Right. Make it Fast.‚Äù mantra, this code sits firmly in the ‚ÄúMake it Work‚Äù bucket.\n\n\n\n\n\nGet Kokomo city borders from 2014 through 2020\n# get kokomo boundaries in 2020\nkokomo_2020 &lt;- places(cb = TRUE, year = 2020) %&gt;%\n  filter(str_detect(NAMELSAD, \"Kokomo city\"))\n\n# write a loop to get kokomo boundaries for each year from 2013 to 2020\nkokomo_boundaries &lt;- map_dfr(2014:2020, ~{\n  places(state = \"IN\", cb = TRUE, year = .x)\n}, .id = \"year\") %&gt;%\n  filter(str_detect(NAME, \"Kokomo\"))\n\n# Add the correct 'year' column \nkokomo_boundaries &lt;- kokomo_boundaries %&gt;% mutate(year = rep(2014:2020, each = nrow(kokomo_boundaries) / 7))\n\n# kokomo census tracts in 2020\nkokomo_2020_tracts &lt;- tracts(state = \"IN\", county = \"Howard\", year = 2020)\n\n# split the kokomo_boundaries file into dataframes of each year of the data\nkokomo_boundaries_2019 &lt;- kokomo_boundaries %&gt;%\n  filter(year == 2019)\nkokomo_boundaries_2018 &lt;- kokomo_boundaries %&gt;%\n  filter(year == 2018)\nkokomo_boundaries_2017 &lt;- kokomo_boundaries %&gt;%\n  filter(year == 2017)\nkokomo_boundaries_2016 &lt;- kokomo_boundaries %&gt;%\n  filter(year == 2016)\nkokomo_boundaries_2015 &lt;- kokomo_boundaries %&gt;%\n  filter(year == 2015)\nkokomo_boundaries_2014 &lt;- kokomo_boundaries %&gt;%\n  filter(year == 2014)\n\n\n\n\nMake a plot of Kokomo city limits from 2014 through 2020\n# plot the city limits\n# add a background map\nkokomo_lims &lt;- ggplot() + \n  geom_sf(data = kokomo_2020_tracts, fill = NA, color = \"grey\") +\n  geom_sf(data = kokomo_2020, fill = NA, color = \"red\") + \n  geom_sf(data = kokomo_boundaries_2019, fill = NA, color = \"blue\") +\n  geom_sf(data = kokomo_boundaries_2018, fill = NA, color = \"green\") +\n  geom_sf(data = kokomo_boundaries_2017, fill = NA, color = \"purple\") +\n  geom_sf(data = kokomo_boundaries_2016, fill = NA, color = \"orange\") +\n  geom_sf(data = kokomo_boundaries_2015, fill = NA, color = \"brown\") +\n  geom_sf(data = kokomo_boundaries_2014, fill = NA, color = \"black\") +\n  # geom_sf(data = kokomo_boundaries, aes(fill = year), color = \"black\") +\n  theme_void()\n\n# add a title to the map\n# add a legend showing that the 2014 boundaries are in black and the 2015-2020 boundaries are in red\nkokomo_lims + labs(title = \"  Kokomo City Limits 2014-2020\", \n                   subtitle = '  2014 boundaries in black; 2015-2020 in red',\n                   caption = 'Howard County Census tracts in grey ')\n\n\n\n\n\n\n\n\nFigure¬†3: Kokomo‚Äôs city limits each year\n\n\n\n\n\nThe boundaries for 2014 are show in black, and the boundaries for years 2015-2020 are showing in red. You can clearly see that between 2014 and 2015, the city expanded to the east and south. However, this expansion doesn‚Äôt appear to have pulled in a significant population addition."
  },
  {
    "objectID": "posts/2024-12-14-kokomo-annexation/index.html#bringing-in-shapefiles-for-earlier-years",
    "href": "posts/2024-12-14-kokomo-annexation/index.html#bringing-in-shapefiles-for-earlier-years",
    "title": "Annexation Station",
    "section": "Bringing in Shapefiles for Earlier Years",
    "text": "Bringing in Shapefiles for Earlier Years\nNext, I imported shapefiles for Kokomo‚Äôs city limits for years before 2014. These files were downloaded from the Census Bureau TIGER Shapefiles website. I used the sf package to read in the shapefiles and plot them with the previously shown boundaries.\n\n\nRead in shapefiles for Kokomo‚Äôs city limits for years before 2014\n# read in shapefiles for Kokomo's city limits for years before 2014\n\n# 2013\nkokomo_boundaries_2013 &lt;- st_read(\"tl_2013_18_place//tl_2013_18_place.shp\")\n\nkokomo_boundaries_2013 &lt;- kokomo_boundaries_2013 %&gt;%\n  filter(str_detect(NAME, \"Kokomo\"))\n\n# 2012\nkokomo_boundaries_2012 &lt;- st_read(\"tl_2012_18_place//tl_2012_18_place.shp\")\n\nkokomo_boundaries_2012 &lt;- kokomo_boundaries_2012 %&gt;%\n  filter(str_detect(NAME, \"Kokomo\"))\n\n# 2011\nkokomo_boundaries_2011 &lt;- st_read(\"tl_2011_18_place//tl_2011_18_place.shp\")\n\nkokomo_boundaries_2011 &lt;- kokomo_boundaries_2011 %&gt;%\n  filter(str_detect(NAME, \"Kokomo\"))\n\n# 2010\nkokomo_boundaries_2010 &lt;- st_read(\"tl_2010_18_place10//tl_2010_18_place10.shp\")\n\nkokomo_boundaries_2010 &lt;- kokomo_boundaries_2010 %&gt;%\n  filter(str_detect(NAME10, \"Kokomo\"))\n\n\n\n\nPlot the city limits each year, 2010-2020\n# plot the city limits\n# add a background map\nkokomo_lims &lt;- ggplot() + \n  geom_sf(data = kokomo_2020_tracts, fill = NA, color = \"grey\") +\n  geom_sf(data = kokomo_2020, fill = NA, color = \"red\") + \n  geom_sf(data = kokomo_boundaries_2019, fill = NA, color = \"blue\") +\n  geom_sf(data = kokomo_boundaries_2018, fill = NA, color = \"green\") +\n  geom_sf(data = kokomo_boundaries_2017, fill = NA, color = \"purple\") +\n  geom_sf(data = kokomo_boundaries_2016, fill = NA, color = \"orange\") +\n  geom_sf(data = kokomo_boundaries_2015, fill = NA, color = \"brown\") +\n  geom_sf(data = kokomo_boundaries_2014, fill = NA, color = \"black\") +\n  geom_sf(data = kokomo_boundaries_2013, fill = NA, color = \"darkgreen\") +\n  geom_sf(data = kokomo_boundaries_2012, fill = NA, color = \"black\") +\n  geom_sf(data = kokomo_boundaries_2011, fill = NA, color = \"dodgerblue2\") +\n  geom_sf(data = kokomo_boundaries_2010, fill = NA, color = \"dodgerblue2\") +\n  theme_void()\n\n# add a title to the map\nkokomo_lims + labs(title = \"  Kokomo City Limits 2010-2020\", \n                   subtitle = '  2010-2011 boundaries in blue\n  2012-2014 boundaries in black \n  2015-2020 in red',\n                   caption = 'Howard County Census tracts in grey ')\n\n\n\n\n\n\n\n\nFigure¬†4: Kokomo‚Äôs city limits each year, 2010-2020\n\n\n\n\n\nBingo!\nJust as the line chart of year-over-year population change showed, the city limits expanded significantly between 2011 and 2012, then expanded even further in 2015.\nThat increase of over 8,000 people in one year was likely due to annexation of new land, not a sudden population boom. As a double-check, some local news articles from the time confirm my initial suspicion."
  },
  {
    "objectID": "posts/2024-12-14-kokomo-annexation/index.html#conclusion",
    "href": "posts/2024-12-14-kokomo-annexation/index.html#conclusion",
    "title": "Annexation Station",
    "section": "Conclusion",
    "text": "Conclusion\nSo, what‚Äôs the solution? There are more advanced techniques that attempt to hold the geographic boundaries steady over time, but that‚Äôs outside the scope of this post. Additionally, you could lean on the Census Bureau‚Äôs population estimates program for more granular population change data.\nA good alternative is to use either counties or county subdivisions (townships) to approximate the same area over time. Center Township in Howard County contains most of Kokomo. Here is the population over time for Center Township. Notice how stable it is.\n\n\nGet population of Center Township, Howard County, Indiana\n# get annual population estimates for Center Township\nyears &lt;- c(2010:2023)\nnames(years) &lt;- years\n\ncenter_by_year &lt;- map_dfr(years, ~{\n  get_acs(\n    geography = \"county subdivision\",\n    variables = \"B01001_001\",\n    state = \"IN\",\n    survey = \"acs5\",\n    year = .x\n  )\n}, .id = \"year\") %&gt;%\n  filter(\n    NAME == 'Center township, Howard County, Indiana'\n  )\n\n\n\n\nPlot Center Township‚Äôs population\n# plot a line chart of center township\nggplot(center_by_year, aes(x = year, y = estimate, group = 1)) +\n  geom_line(color = 'dodgerblue') +\n  geom_point(color = 'dodgerblue') +\n  labs(title = \"Center Township, Howard County\",\n       subtitle = \"Population over time\",\n       x = \"Year\",\n       y = \"Population\") +\n  theme_ipsum() +\n  scale_y_continuous(labels = scales::comma, limits = c(0, 60000)) +\n  scale_x_discrete(breaks = seq(2010, 2023, 2))\n\n\n\n\n\n\n\n\nFigure¬†5: Center Township‚Äôs population, 2010-2023\n\n\n\n\n\nCity boundaries change frequently. When looking at population change‚Äìor any metric that uses population as a denominator‚Äìit‚Äôs import to keep the possibility of annexation in mind.\nThe tidycensus, sf, and tigris packages are a powerful toolkit for ensuring the results of your analysis can be placed in the proper context."
  },
  {
    "objectID": "blogposts.html",
    "href": "blogposts.html",
    "title": "Blog",
    "section": "",
    "text": "Update: Clark‚Äôs 2024 season still stands out\n\n\n\nR\n\nsports\n\nObservable\n\n\n\nRe-visiting her rookie campaign‚Äôs offensive production\n\n\n\nAaron Olson\n\n\nSep 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnexation Station\n\n\n\nR\n\ncensus\n\n\n\nLookout for boundary changes when population totals jump\n\n\n\nAaron Olson\n\n\nDec 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy personal tidycensus guide\n\n\n\nR\n\ncensus\n\n\n\nAnalyze Census data ten times faster\n\n\n\nAaron Olson\n\n\nNov 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaitlin Clark‚Äôs Historic 2024\n\n\n\nR\n\nsports\n\n\n\nComparing her rookie year to the last five WNBA and NBA seasons\n\n\n\nAaron Olson\n\n\nSep 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nPeak Population Years for Every County\n\n\n\nR\n\ncensus\n\n\n\nAnalyzing 100 years of population data\n\n\n\nAaron Olson\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello, World\n\n\n\nQuarto\n\nR\n\n\n\nWelcome to my blog\n\n\n\nAaron Olson\n\n\nAug 1, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-08-01-hello-world/index.html",
    "href": "posts/2024-08-01-hello-world/index.html",
    "title": "Hello, World",
    "section": "",
    "text": "Hey there! üëã\nWelcome to my blog. Special thanks to Samantha Csik‚Äôs wonderful guide on setting up a blog on a Quarto website.\nDon‚Äôt worry, I come in peace."
  },
  {
    "objectID": "posts/2024-08-01-hello-world/index.html#viewing-source-code-on-this-site",
    "href": "posts/2024-08-01-hello-world/index.html#viewing-source-code-on-this-site",
    "title": "Hello, World",
    "section": "üîé Viewing source code on this site",
    "text": "üîé Viewing source code on this site\nData analyses in the blog posts on this site are usually conducted with the R coding language. To view the code that generates the analysis, click the ‚Äú&gt; Code‚Äù dropdown button above each chunk.\nThere is also a button on the top right corner of every post with code-folding enabled to globally expand or collapse all code chunks.\n\nCode Chunk Example\nFor example, the code that loads the iris dataset and generates the plot below can be expanded or collapsed by the ‚Äú&gt; Code‚Äù dropdown button.\n\n\nCode\nboxplot(Sepal.Length~Species,\n        data=iris,\n        main='Sepal Length by Species',\n        xlab='Species',\n        ylab='Sepal Length',\n        col='steelblue',\n        border='black')\n\n\n\n\n\nA boxplot of the iris dataset\n\n\n\n\nIt‚Äôs a useful feature of Quarto that allows for documents to be consumed easily by both technical and non-technical readers.\nHappy reading üòÅ"
  },
  {
    "objectID": "posts/2024-08-26-county-max-population/index.html",
    "href": "posts/2024-08-26-county-max-population/index.html",
    "title": "Peak Population Years for Every County",
    "section": "",
    "text": "This is an exploration of when population peaked in each county in the U.S. between 1920 and 2020.\nKeep in mind that some county borders may have changed during this time period, so it‚Äôs possible that some change in population is due to border change rather than change in the number of people within the same boundaries.\n1920 was selected as a start year for two reasons. First, this allows us to view population change over the last century. Second, Most significant county border changes had been completed by 1920.\nFor more about how borders have changed over time, check out the Atlas of County Historical Boundaries. Data was retrieved through the National Historical Geographic Information System.\nThe code beow details the steps to produce this fascinating map. Enjoy!\n\n\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(mapview)\nlibrary(tigris)\nlibrary(sf)\n\n\n# import data\ncounty_pops_1900_2020 &lt;- read_csv(\"Raw Data/county_pops_1900_2020.csv\")\n\n# view structure and check for NAs\nsummary(county_pops_1900_2020)\n\n    GEOID               cty               pop_1900          pop_1910      \n Length:3134        Length:3134        Min.   :      0   Min.   :      0  \n Class :character   Class :character   1st Qu.:   6321   1st Qu.:   9255  \n Mode  :character   Mode  :character   Median :  15083   Median :  16818  \n                                       Mean   :  24114   Mean   :  29362  \n                                       3rd Qu.:  24788   3rd Qu.:  27157  \n                                       Max.   :2050600   Max.   :2762522  \n                                                                          \n    pop_1920          pop_1930          pop_1940          pop_1950      \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :      0  \n 1st Qu.:   9830   1st Qu.:   9964   1st Qu.:  10279   1st Qu.:   9762  \n Median :  17376   Median :  17493   Median :  18467   Median :  18354  \n Mean   :  33764   Mean   :  39250   Mean   :  42104   Mean   :  48155  \n 3rd Qu.:  28397   3rd Qu.:  30305   3rd Qu.:  32742   3rd Qu.:  35269  \n Max.   :3053017   Max.   :3982123   Max.   :4063342   Max.   :4508792  \n                                                                        \n    pop_1960          pop_1970          pop_1980          pop_1990      \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :    107  \n 1st Qu.:   9212   1st Qu.:   9151   1st Qu.:  10357   1st Qu.:  10370  \n Median :  18118   Median :  18478   Median :  21617   Median :  22239  \n Mean   :  57151   Mean   :  64817   Mean   :  72276   Mean   :  79347  \n 3rd Qu.:  39030   3rd Qu.:  42520   3rd Qu.:  50668   3rd Qu.:  54798  \n Max.   :6038771   Max.   :7032075   Max.   :7477503   Max.   :8863164  \n                                                                        \n    pop_2000          pop_2010          pop_2020       \n Min.   :     67   Min.   :     82   Min.   :      64  \n 1st Qu.:  11282   1st Qu.:  11180   1st Qu.:   10896  \n Median :  24705   Median :  25930   Median :   25781  \n Mean   :  89787   Mean   :  98489   Mean   :  105821  \n 3rd Qu.:  61949   3rd Qu.:  67020   3rd Qu.:   68100  \n Max.   :9519338   Max.   :9818605   Max.   :10014009  \n                                     NA's   :3         \n\n\n\n\nThere are 3,134 rows and all of the population columns are numeric. However, three nulls exist in the ‚Äòpop_2020‚Äô column; those should be investigated.\n\n\nLuckily, there are no duplicate county GEOIDs, so no need for clean up there.\n\n# check if there are any duplicate GEOIDs\nany(duplicated(county_pops_1900_2020$GEOID))\n\n[1] FALSE\n\n\n\n\n\nIt looks like two Census Areas (county equivalents) in Alaska and one county in South Dakota have ‚ÄòNaN‚Äô in the 2020 population column rather than values. These Alaska Census Areas were abolished between 2010 and 2020 and replaced with other areas, while Shannon County, SD was renamed as Oglala Lakota County.\nThey shouldn‚Äôt cause too much of a problem, since we are only seeking the maximum population year for each county, but important to keep in mind when viewing the results.\n\n# show only rows with NAs in 'pop_2020' column\ncounty_pops_1900_2020[is.na(county_pops_1900_2020$pop_2020), ]\n\n\n  \n\n\n\n\n\n\nThis improves readability and allows for grouping by state and joining on Census region to the state later on\n\n# split the 'cty' field\ncounty_pops_1900_2020[c('county', 'state')] &lt;- str_split_fixed(county_pops_1900_2020$cty, ',', 2)\n\n# view results\ncounty_pops_1900_2020 %&gt;% select(GEOID, cty, county, state) %&gt;% head()\n\n\n  \n\n\n\n\n\n\nSince we are only concerned with data from 1920 through 2020, these columns can be dropped\n\n# select only needed columns\ncounty_pops_1920_2020 &lt;- county_pops_1900_2020 %&gt;%\n  select (\n    -pop_1900,\n    -pop_1910\n  )\n\n\n\n\n\n\nNow that the cleaning is out of the way, let‚Äôs find those max population years!\n\n# Find max of each county by reshaping data\n\nlong_county_pops_1920_2020 &lt;- county_pops_1920_2020 %&gt;%\n  pivot_longer(\n    cols = !c(GEOID, cty, county, state),\n    names_to = \"year\",\n    values_to = \"population\"\n  )\n\n# Make a dataframe of the max population years\n\nmax_population_years &lt;- long_county_pops_1920_2020 %&gt;%\n  group_by(cty) %&gt;%\n  slice_max(population, n = 1, with_ties = FALSE) %&gt;%\n  arrange(desc(population)) \n\nmax_population_years\n\n\n  \n\n\n\n\n\nIt‚Äôs not surprising that 2020 is the most common peak population year: the U.S. population has (generally) steadily increased over the past 100 years and so you‚Äôd expect 2020 to be the most common peak year. What is surprising is that 1920 is the second most common peak year behind 2020 with 454 counties peaking that year. In fact, 1920, 1930, and 1940 were the 2nd, 4th, and 5th most common peak population year.\n\n# Group by max population year and count\ncty_by_max_yr &lt;- max_population_years %&gt;%\n  group_by(year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\ncty_by_max_yr$year &lt;- str_replace_all(cty_by_max_yr$year, \"pop_\", \"\")\n\n# make a bar chart of the result\ncty_by_max_yr %&gt;%\n  ggplot(\n    aes(x = year, y = number_of_counties)\n  ) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = number_of_counties), hjust = 0.5, vjust = -0.5, color= \"black\", size = 3) +\n  labs(title = \"How many counties peaked each year?\", \n       subtitle = \"All U.S. Counties\", \n       y = \"N Counties\", \n       x = \"Peak Population Year\") +\n  scale_y_continuous(limits = c(0, 1500)) +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\n\n\nTo untangle why this is occuring, it‚Äôs helpful to break the data down by region. Here, I join on Census region and division definitions.\n\n# Import census regions and divisions sheet\ncensus_regions &lt;- read_csv(\"Raw Data/census_regions.csv\")\n\n# Trim whitespace from max_population_years to facilitate merging\nmax_population_years$state &lt;- trimws(max_population_years$state)\n\n# Join regions and divisions to max_population_years\nmax_population_years &lt;- merge(x = max_population_years, \n                              y = census_regions,\n                              by.x = \"state\",\n                              by.y = \"State\")\n\nThere are significant differences between regions in the distribution of peak population years. The Midwest really stands out here. In the Midwest, 35% of counties had a peak population year in 1920 or 1930. That‚Äôs compared to 18% of Southern counties, 12% of Western counties, and just 5% of Northeastern counties.\nThe West also stands out, but for the opposite reason. Over 60% of counties in the West reached their peak population year in 2020. That‚Äôs compared to just 28% of Midwestern counties.\n\n# Group by Region and max year\nregion_cty_by_max_yr &lt;- max_population_years %&gt;%\n  group_by(Region, year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\nregion_cty_by_max_yr$year &lt;- str_replace_all(region_cty_by_max_yr$year, \"pop_\", \"\")\n\n# Calculate percentage\nregion_cty_by_max_yr &lt;- region_cty_by_max_yr %&gt;%\n  group_by(Region) %&gt;%\n  mutate(percentage = number_of_counties / sum(number_of_counties))\n\n# Faceted bar chart by Region\nregion_cty_by_max_yr %&gt;%\n  ggplot(\n    aes(x = year, y = percentage, fill = Region)\n  ) +\n  geom_bar(stat = \"identity\") +\n  #geom_text(aes(label = number_of_counties), hjust = 0.5, vjust = -0.5, color= \"black\", size = 3) +\n  labs(title = \"What % of Counties Peaked Each Year?\", \n       subtitle = \"All U.S. Counties - by Region\", \n       y = \"Percentage\", \n       x = \"Peak Population Year\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  #theme_ipsum() +\n  facet_wrap(~ Region, nrow = 2)\n\n\n\n\n\n\n\n\nThere is also significant variation in peak population years within the Midwest itself. The Midwest region is broken down into the West North Central (Dakotas, Nebraska, Kansas, Minnesota, Iowa, Missouri) and East North Central (Wisconsin, Illinois, Michigan, Indiana, Ohio) divisions. Half of the counties in the West North Central division peaked in either 1920 or 1930.\nKeep in mind that it‚Äôs possible some counties peaked before 1920, but our data frame is restricted to the last 100 years only.\n\n# Group by Division (Midwest Only) and max year\nmw_cty_by_max_yr &lt;- max_population_years %&gt;%\n  filter(Region == \"Midwest\") %&gt;%\n  group_by(Division, year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\nmw_cty_by_max_yr$year &lt;- str_replace_all(mw_cty_by_max_yr$year, \"pop_\", \"\")\n\n# Calculate percentage\nmw_cty_by_max_yr &lt;- mw_cty_by_max_yr %&gt;%\n  group_by(Division) %&gt;%\n  mutate(percentage = number_of_counties / sum(number_of_counties))\n\n# Faceted bar chart by Region\nmw_cty_by_max_yr %&gt;%\n  ggplot(\n    aes(x = year, y = percentage, fill = Division)\n  ) +\n  geom_bar(stat = \"identity\") +\n  #geom_text(aes(label = number_of_counties), hjust = 0.5, vjust = -0.5, color= \"black\", size = 3) +\n  labs(title = \"What % of Counties Peaked Each Year?\", \n       subtitle = \"Midwest Counties - by Division\", \n       y = \"Percentage\", \n       x = \"Peak Population Year\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  #theme_ipsum() +\n  facet_wrap(~ Division, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nAlthough not a state, I did not know that Washington, D.C.‚Äôs population peaked in 1950. Beyond that, those ‚ÄúWest North Central‚Äù Midwestern states have a comparatively high percentage of counties peaking in 1930 and 1920. In North Dakota, 43% of counties peaked in 1930.\n\n# Group by state and max year\nstate_cty_by_max_yr &lt;- max_population_years %&gt;%\n  group_by(state, year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\nstate_cty_by_max_yr$year &lt;- str_replace_all(state_cty_by_max_yr$year, \"pop_\", \"\")\n\n# Calculate percentage\nstate_cty_by_max_yr &lt;- state_cty_by_max_yr %&gt;%\n  group_by(state) %&gt;%\n  mutate(percentage = number_of_counties / sum(number_of_counties))\n\n# Show states with high percent of counties peaking before 2020\nstate_cty_by_max_yr %&gt;%\n  filter(\n    year != '2020'\n  ) %&gt;%\n  arrange(desc(percentage))\n\n\n  \n\n\n\n\n\n\nCheck out the map below. What interesting trends do you see?\n\n# get county geographies\ncounty_geo &lt;- tigris::counties(cb = TRUE, resolution = '20m')\n\n\n# join county geographies to peak population year data\nstatic_map_data &lt;- merge(x = county_geo,\n                         y = max_population_years,\n                         by = \"GEOID\")\n\n# remove Alaska/Hawaii for cleaner mapping\nstatic_map_data &lt;- static_map_data %&gt;%\n  filter(!(state %in% c(\"Alaska\", \"Hawaii\")))\n\n# replace \"pop_\" in peak year column and change to numeric\nstatic_map_data$year &lt;- str_replace_all(static_map_data$year, \"pop_\", \"\")\n\nstatic_map_data$year &lt;- as.numeric(static_map_data$year)\n\n# Make a map\nggplot(data = static_map_data, aes(fill = year)) + \n  geom_sf() + \n  labs(title = \"  Peak Population Years of U.S. Counties\",\n       subtitle = \"   between 1920 and 2020\",\n       caption = \"Source: NHGIS\",\n       fill = \"Peak Year  \") + \n  theme_void() + \n  scale_fill_continuous(type = \"viridis\",\n                        breaks = c(1920, 1940, 1960, 1980, 2000, 2020))"
  },
  {
    "objectID": "posts/2024-08-26-county-max-population/index.html#import-data-and-view-its-structure",
    "href": "posts/2024-08-26-county-max-population/index.html#import-data-and-view-its-structure",
    "title": "Peak Population Years for Every County",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(mapview)\nlibrary(tigris)\nlibrary(sf)\n\n\n# import data\ncounty_pops_1900_2020 &lt;- read_csv(\"Raw Data/county_pops_1900_2020.csv\")\n\n# view structure and check for NAs\nsummary(county_pops_1900_2020)\n\n    GEOID               cty               pop_1900          pop_1910      \n Length:3134        Length:3134        Min.   :      0   Min.   :      0  \n Class :character   Class :character   1st Qu.:   6321   1st Qu.:   9255  \n Mode  :character   Mode  :character   Median :  15083   Median :  16818  \n                                       Mean   :  24114   Mean   :  29362  \n                                       3rd Qu.:  24788   3rd Qu.:  27157  \n                                       Max.   :2050600   Max.   :2762522  \n                                                                          \n    pop_1920          pop_1930          pop_1940          pop_1950      \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :      0  \n 1st Qu.:   9830   1st Qu.:   9964   1st Qu.:  10279   1st Qu.:   9762  \n Median :  17376   Median :  17493   Median :  18467   Median :  18354  \n Mean   :  33764   Mean   :  39250   Mean   :  42104   Mean   :  48155  \n 3rd Qu.:  28397   3rd Qu.:  30305   3rd Qu.:  32742   3rd Qu.:  35269  \n Max.   :3053017   Max.   :3982123   Max.   :4063342   Max.   :4508792  \n                                                                        \n    pop_1960          pop_1970          pop_1980          pop_1990      \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :    107  \n 1st Qu.:   9212   1st Qu.:   9151   1st Qu.:  10357   1st Qu.:  10370  \n Median :  18118   Median :  18478   Median :  21617   Median :  22239  \n Mean   :  57151   Mean   :  64817   Mean   :  72276   Mean   :  79347  \n 3rd Qu.:  39030   3rd Qu.:  42520   3rd Qu.:  50668   3rd Qu.:  54798  \n Max.   :6038771   Max.   :7032075   Max.   :7477503   Max.   :8863164  \n                                                                        \n    pop_2000          pop_2010          pop_2020       \n Min.   :     67   Min.   :     82   Min.   :      64  \n 1st Qu.:  11282   1st Qu.:  11180   1st Qu.:   10896  \n Median :  24705   Median :  25930   Median :   25781  \n Mean   :  89787   Mean   :  98489   Mean   :  105821  \n 3rd Qu.:  61949   3rd Qu.:  67020   3rd Qu.:   68100  \n Max.   :9519338   Max.   :9818605   Max.   :10014009  \n                                     NA's   :3         \n\n\n\n\nThere are 3,134 rows and all of the population columns are numeric. However, three nulls exist in the ‚Äòpop_2020‚Äô column; those should be investigated.\n\n\nLuckily, there are no duplicate county GEOIDs, so no need for clean up there.\n\n# check if there are any duplicate GEOIDs\nany(duplicated(county_pops_1900_2020$GEOID))\n\n[1] FALSE\n\n\n\n\n\nIt looks like two Census Areas (county equivalents) in Alaska and one county in South Dakota have ‚ÄòNaN‚Äô in the 2020 population column rather than values. These Alaska Census Areas were abolished between 2010 and 2020 and replaced with other areas, while Shannon County, SD was renamed as Oglala Lakota County.\nThey shouldn‚Äôt cause too much of a problem, since we are only seeking the maximum population year for each county, but important to keep in mind when viewing the results.\n\n# show only rows with NAs in 'pop_2020' column\ncounty_pops_1900_2020[is.na(county_pops_1900_2020$pop_2020), ]\n\n\n  \n\n\n\n\n\n\nThis improves readability and allows for grouping by state and joining on Census region to the state later on\n\n# split the 'cty' field\ncounty_pops_1900_2020[c('county', 'state')] &lt;- str_split_fixed(county_pops_1900_2020$cty, ',', 2)\n\n# view results\ncounty_pops_1900_2020 %&gt;% select(GEOID, cty, county, state) %&gt;% head()\n\n\n  \n\n\n\n\n\n\nSince we are only concerned with data from 1920 through 2020, these columns can be dropped\n\n# select only needed columns\ncounty_pops_1920_2020 &lt;- county_pops_1900_2020 %&gt;%\n  select (\n    -pop_1900,\n    -pop_1910\n  )"
  },
  {
    "objectID": "posts/2024-08-26-county-max-population/index.html#analysis",
    "href": "posts/2024-08-26-county-max-population/index.html#analysis",
    "title": "Peak Population Years for Every County",
    "section": "",
    "text": "Now that the cleaning is out of the way, let‚Äôs find those max population years!\n\n# Find max of each county by reshaping data\n\nlong_county_pops_1920_2020 &lt;- county_pops_1920_2020 %&gt;%\n  pivot_longer(\n    cols = !c(GEOID, cty, county, state),\n    names_to = \"year\",\n    values_to = \"population\"\n  )\n\n# Make a dataframe of the max population years\n\nmax_population_years &lt;- long_county_pops_1920_2020 %&gt;%\n  group_by(cty) %&gt;%\n  slice_max(population, n = 1, with_ties = FALSE) %&gt;%\n  arrange(desc(population)) \n\nmax_population_years\n\n\n  \n\n\n\n\n\nIt‚Äôs not surprising that 2020 is the most common peak population year: the U.S. population has (generally) steadily increased over the past 100 years and so you‚Äôd expect 2020 to be the most common peak year. What is surprising is that 1920 is the second most common peak year behind 2020 with 454 counties peaking that year. In fact, 1920, 1930, and 1940 were the 2nd, 4th, and 5th most common peak population year.\n\n# Group by max population year and count\ncty_by_max_yr &lt;- max_population_years %&gt;%\n  group_by(year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\ncty_by_max_yr$year &lt;- str_replace_all(cty_by_max_yr$year, \"pop_\", \"\")\n\n# make a bar chart of the result\ncty_by_max_yr %&gt;%\n  ggplot(\n    aes(x = year, y = number_of_counties)\n  ) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = number_of_counties), hjust = 0.5, vjust = -0.5, color= \"black\", size = 3) +\n  labs(title = \"How many counties peaked each year?\", \n       subtitle = \"All U.S. Counties\", \n       y = \"N Counties\", \n       x = \"Peak Population Year\") +\n  scale_y_continuous(limits = c(0, 1500)) +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\n\n\nTo untangle why this is occuring, it‚Äôs helpful to break the data down by region. Here, I join on Census region and division definitions.\n\n# Import census regions and divisions sheet\ncensus_regions &lt;- read_csv(\"Raw Data/census_regions.csv\")\n\n# Trim whitespace from max_population_years to facilitate merging\nmax_population_years$state &lt;- trimws(max_population_years$state)\n\n# Join regions and divisions to max_population_years\nmax_population_years &lt;- merge(x = max_population_years, \n                              y = census_regions,\n                              by.x = \"state\",\n                              by.y = \"State\")\n\nThere are significant differences between regions in the distribution of peak population years. The Midwest really stands out here. In the Midwest, 35% of counties had a peak population year in 1920 or 1930. That‚Äôs compared to 18% of Southern counties, 12% of Western counties, and just 5% of Northeastern counties.\nThe West also stands out, but for the opposite reason. Over 60% of counties in the West reached their peak population year in 2020. That‚Äôs compared to just 28% of Midwestern counties.\n\n# Group by Region and max year\nregion_cty_by_max_yr &lt;- max_population_years %&gt;%\n  group_by(Region, year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\nregion_cty_by_max_yr$year &lt;- str_replace_all(region_cty_by_max_yr$year, \"pop_\", \"\")\n\n# Calculate percentage\nregion_cty_by_max_yr &lt;- region_cty_by_max_yr %&gt;%\n  group_by(Region) %&gt;%\n  mutate(percentage = number_of_counties / sum(number_of_counties))\n\n# Faceted bar chart by Region\nregion_cty_by_max_yr %&gt;%\n  ggplot(\n    aes(x = year, y = percentage, fill = Region)\n  ) +\n  geom_bar(stat = \"identity\") +\n  #geom_text(aes(label = number_of_counties), hjust = 0.5, vjust = -0.5, color= \"black\", size = 3) +\n  labs(title = \"What % of Counties Peaked Each Year?\", \n       subtitle = \"All U.S. Counties - by Region\", \n       y = \"Percentage\", \n       x = \"Peak Population Year\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  #theme_ipsum() +\n  facet_wrap(~ Region, nrow = 2)\n\n\n\n\n\n\n\n\nThere is also significant variation in peak population years within the Midwest itself. The Midwest region is broken down into the West North Central (Dakotas, Nebraska, Kansas, Minnesota, Iowa, Missouri) and East North Central (Wisconsin, Illinois, Michigan, Indiana, Ohio) divisions. Half of the counties in the West North Central division peaked in either 1920 or 1930.\nKeep in mind that it‚Äôs possible some counties peaked before 1920, but our data frame is restricted to the last 100 years only.\n\n# Group by Division (Midwest Only) and max year\nmw_cty_by_max_yr &lt;- max_population_years %&gt;%\n  filter(Region == \"Midwest\") %&gt;%\n  group_by(Division, year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\nmw_cty_by_max_yr$year &lt;- str_replace_all(mw_cty_by_max_yr$year, \"pop_\", \"\")\n\n# Calculate percentage\nmw_cty_by_max_yr &lt;- mw_cty_by_max_yr %&gt;%\n  group_by(Division) %&gt;%\n  mutate(percentage = number_of_counties / sum(number_of_counties))\n\n# Faceted bar chart by Region\nmw_cty_by_max_yr %&gt;%\n  ggplot(\n    aes(x = year, y = percentage, fill = Division)\n  ) +\n  geom_bar(stat = \"identity\") +\n  #geom_text(aes(label = number_of_counties), hjust = 0.5, vjust = -0.5, color= \"black\", size = 3) +\n  labs(title = \"What % of Counties Peaked Each Year?\", \n       subtitle = \"Midwest Counties - by Division\", \n       y = \"Percentage\", \n       x = \"Peak Population Year\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  #theme_ipsum() +\n  facet_wrap(~ Division, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nAlthough not a state, I did not know that Washington, D.C.‚Äôs population peaked in 1950. Beyond that, those ‚ÄúWest North Central‚Äù Midwestern states have a comparatively high percentage of counties peaking in 1930 and 1920. In North Dakota, 43% of counties peaked in 1930.\n\n# Group by state and max year\nstate_cty_by_max_yr &lt;- max_population_years %&gt;%\n  group_by(state, year) %&gt;%\n  summarise(number_of_counties = n())\n\n# replace \"pop_\" for cleaner formatting\nstate_cty_by_max_yr$year &lt;- str_replace_all(state_cty_by_max_yr$year, \"pop_\", \"\")\n\n# Calculate percentage\nstate_cty_by_max_yr &lt;- state_cty_by_max_yr %&gt;%\n  group_by(state) %&gt;%\n  mutate(percentage = number_of_counties / sum(number_of_counties))\n\n# Show states with high percent of counties peaking before 2020\nstate_cty_by_max_yr %&gt;%\n  filter(\n    year != '2020'\n  ) %&gt;%\n  arrange(desc(percentage))\n\n\n  \n\n\n\n\n\n\nCheck out the map below. What interesting trends do you see?\n\n# get county geographies\ncounty_geo &lt;- tigris::counties(cb = TRUE, resolution = '20m')\n\n\n# join county geographies to peak population year data\nstatic_map_data &lt;- merge(x = county_geo,\n                         y = max_population_years,\n                         by = \"GEOID\")\n\n# remove Alaska/Hawaii for cleaner mapping\nstatic_map_data &lt;- static_map_data %&gt;%\n  filter(!(state %in% c(\"Alaska\", \"Hawaii\")))\n\n# replace \"pop_\" in peak year column and change to numeric\nstatic_map_data$year &lt;- str_replace_all(static_map_data$year, \"pop_\", \"\")\n\nstatic_map_data$year &lt;- as.numeric(static_map_data$year)\n\n# Make a map\nggplot(data = static_map_data, aes(fill = year)) + \n  geom_sf() + \n  labs(title = \"  Peak Population Years of U.S. Counties\",\n       subtitle = \"   between 1920 and 2020\",\n       caption = \"Source: NHGIS\",\n       fill = \"Peak Year  \") + \n  theme_void() + \n  scale_fill_continuous(type = \"viridis\",\n                        breaks = c(1920, 1940, 1960, 1980, 2000, 2020))"
  },
  {
    "objectID": "posts/2024-09-29-caitlin-clark-2024/index.html",
    "href": "posts/2024-09-29-caitlin-clark-2024/index.html",
    "title": "Caitlin Clark‚Äôs Historic 2024",
    "section": "",
    "text": "This post shows the code for my analysis of Caitlin Clark‚Äôs historic 2024 WNBA season.\nI calculated two metrics ‚Äòpoint shares‚Äô (the percentage of a team‚Äôs total points that a player accounts for) and ‚Äòassist shares‚Äô (the percentage of a team‚Äôs total assists that a player accounts for) to compare Clark to the last five seasons of both WNBA and NBA data.\nThe result are these cool scatterplots with NBA and WNBA players‚Äô offensive production in relation to their teams‚Äô output. Incredibly, Clark was the only WNBA or NBA player to account for 40% of their team‚Äôs assists and 20% of the team‚Äôs points in a season in the last five years."
  },
  {
    "objectID": "posts/2024-09-29-caitlin-clark-2024/index.html#wnba-season-analysis",
    "href": "posts/2024-09-29-caitlin-clark-2024/index.html#wnba-season-analysis",
    "title": "Caitlin Clark‚Äôs Historic 2024",
    "section": "2024 WNBA Season Analysis",
    "text": "2024 WNBA Season Analysis\n\n# Total points and assist in 2024 season\nwnba_player_box$athlete_id &lt;- as.character(wnba_player_box$athlete_id)\n\nwnba_pts_assists &lt;- wnba_player_box %&gt;%\n  filter(did_not_play == FALSE,\n         game_id != '401620458') %&gt;%\n  group_by(athlete_id, athlete_display_name, team_id) %&gt;%\n  summarize(total_points = sum(points),\n            total_assists = sum(assists)) %&gt;%\n  arrange(desc(total_points)) \n\nwnba_team_pts_assists &lt;- wnba_team_box %&gt;%\n  filter(game_id != '401620458') %&gt;%\n  group_by(team_id, team_display_name) %&gt;%\n  summarize(\n    total_assists = sum(assists),\n    total_points = sum(team_score)\n  ) %&gt;%\n  arrange(desc(total_points))\n\n# Join player and team dfs together\nplayer_and_team &lt;- merge(x = wnba_pts_assists,\n                         y = wnba_team_pts_assists,\n                         by.x = \"team_id\",\n                         by.y = \"team_id\")\n\n\n# Calculate share of team points and assists\nplayer_and_team &lt;- player_and_team %&gt;%\n  rename(\n    team_assists = total_assists.y,\n    team_points = total_points.y\n  ) %&gt;%\n  mutate(\n    assist_share = total_assists.x/team_assists,\n    points_share = total_points.x/team_points\n  )"
  },
  {
    "objectID": "posts/2024-09-29-caitlin-clark-2024/index.html#scatterplot",
    "href": "posts/2024-09-29-caitlin-clark-2024/index.html#scatterplot",
    "title": "Caitlin Clark‚Äôs Historic 2024",
    "section": "Scatterplot",
    "text": "Scatterplot\n\n# Create scatterplot of points and assists shares\nwnba2024 &lt;- ggplot(player_and_team, aes(x = points_share, y = assist_share)) +\n  geom_point(color = \"black\", fill = \"cornflowerblue\", size = 3, shape = 21, alpha = 0.5) +\n  labs(title = \"2024 WNBA Season: Points and Assists Shares\",\n       subtitle = \"Each dot is one player\",\n       x = \"Share of Team Points\",\n       y = \"Share of Team Assists\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  theme_ipsum(base_size = 15, axis_title_size = 14) +\n  geom_text(x=.225, y=.38, label=\"Caitlin Clark\", color = \"gray16\")  +\n  geom_text(x=.285, y=.08, label=\"A'ja Wilson\", color = \"gray16\") +\n  geom_text(x=.135, y=.378, label=\"Alyssa Thomas\", color = \"gray16\")\n\n# Show plot\nwnba2024"
  },
  {
    "objectID": "posts/2024-09-29-caitlin-clark-2024/index.html#wnba-season-analysis-1",
    "href": "posts/2024-09-29-caitlin-clark-2024/index.html#wnba-season-analysis-1",
    "title": "Caitlin Clark‚Äôs Historic 2024",
    "section": "2019-2024 WNBA Season Analysis",
    "text": "2019-2024 WNBA Season Analysis\n\n# All WNBA Seasons Data\n\nhist_wnba_player_box &lt;- wehoop::load_wnba_player_box(seasons = 2019:2024)\nhist_wnba_team_box &lt;- wehoop::load_wnba_team_box(seasons = 2019:2024)\n\n# Clean data: remove All-Star games' data and only use regular season data\n\nall_star_teams &lt;- c(\n  \"EAST\",\n  \"WEST\",\n  \"Team Parker\",\n  \"Team Delle Donne\",\n  \"Team Wilson\",\n  \"Team Usa\",\n  \"Team WNBA\",\n  \"Team Stewart\",\n  \"Team USA\"\n)\n\nhist_wnba_player_box &lt;- hist_wnba_player_box %&gt;%\n  filter(\n    !team_display_name %in% all_star_teams,\n    season_type == 2\n  )\n\nhist_wnba_team_box &lt;- hist_wnba_team_box %&gt;%\n  filter(\n    !team_display_name %in% all_star_teams,\n    season_type == 2\n  )\n\n# Calculate total points and assists in season\nhist_wnba_pts_assists &lt;- hist_wnba_player_box %&gt;%\n  filter(did_not_play == FALSE) %&gt;%\n  group_by(season, athlete_id, athlete_display_name, team_id) %&gt;%\n  summarize(total_points = sum(points),\n            total_assists = sum(assists)) %&gt;%\n  arrange(desc(total_points)) \n\n\nhist_wnba_team_pts_assists &lt;- hist_wnba_team_box %&gt;%\n  group_by(season, team_id, team_display_name) %&gt;%\n  summarize(\n    total_assists = sum(assists),\n    total_points = sum(team_score)\n  ) %&gt;%\n  arrange(desc(total_points))\n\n\n# Join historical team and player data together\nhist_player_and_team &lt;- merge(x = hist_wnba_pts_assists,\n                              y = hist_wnba_team_pts_assists,\n                              by.x = c(\"season\", \"team_id\"),\n                              by.y = c(\"season\",\"team_id\"))\n\n# Calculate share of team points and assists\nhist_player_and_team &lt;- hist_player_and_team %&gt;%\n  rename(\n    team_assists = total_assists.y,\n    team_points = total_points.y\n  ) %&gt;%\n  mutate(\n    assist_share = total_assists.x/team_assists,\n    points_share = total_points.x/team_points\n  )"
  },
  {
    "objectID": "posts/2024-09-29-caitlin-clark-2024/index.html#nba-wnba-scatterplot",
    "href": "posts/2024-09-29-caitlin-clark-2024/index.html#nba-wnba-scatterplot",
    "title": "Caitlin Clark‚Äôs Historic 2024",
    "section": "NBA-WNBA Scatterplot",
    "text": "NBA-WNBA Scatterplot\n\nnba_wnba_plot &lt;- ggplot(nba_wnba_combined, aes(x = points_share, y = assist_share, color = League)) +\n  geom_point(size = 3, shape = 21, alpha = 0.9) +\n  labs(title = \"2019-2024 NBA/WNBA: Pt. and Asst. Shares\",\n       subtitle = \"Each dot is one player\",\n       x = \"Share of Team Points\",\n       y = \"Share of Team Assists\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  theme_ipsum(base_size = 15, axis_title_size = 14) +\n  geom_text(x=.225, y=.45, label=\"Caitlin Clark (2024)\", color = \"gray16\") +\n  geom_hline(yintercept = .40, color = \"gainsboro\") +\n  geom_vline(xintercept = .20, color = \"gainsboro\")\n\n# Show plot\nnba_wnba_plot"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "These are my various online profiles where you can find code I‚Äôve written or contributed to üòÄ\n\n  \n    \n      \n        \n      \n      Github\n      Various project code and learning notes\n    \n    \n      \n        \n      \n      Observable\n      Data visualization notebooks in JavaScript  \n    \n    \n      \n        \n      \n      Leetcode\n      Skill-building through coding challenges"
  },
  {
    "objectID": "posts/2025-09-21-draft/index.html",
    "href": "posts/2025-09-21-draft/index.html",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "",
    "text": "Last year, I wrote that Caitlin Clark‚Äôs offensive contributions in her 2024 rookie season for the Indiana Fever was unmatched among both WNBA and NBA players since at least 2019. She was the only player in either league over this time span to contribute 40% of a team‚Äôs assists and 20% of a team‚Äôs points in a single season.\nWith the WNBA playoffs in full swing, and the Clark-less Fever making an inspired run, I am re-visiting that analysis.\nThis time, I have expanded the time frame to include that last 10 seasons of WNBA and NBA play as well as the WNBA regular season that just concluded. Data was pulled using the wehoop and hoopR R packages from the Sports Dataverse.\nAlso new this time is the interactive scatterplot below, created with the Observable Plot JavaScript library. There is a companion notebook on the Observable HQ platform, for those interested in creating something similar."
  },
  {
    "objectID": "posts/2025-09-21-draft/index.html#introduction",
    "href": "posts/2025-09-21-draft/index.html#introduction",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "",
    "text": "Last year, I wrote that Caitlin Clark‚Äôs offensive contributions in her 2024 rookie season for the Indiana Fever was unmatched among both WNBA and NBA players since at least 2019. She was the only player in either league over this time span to contribute 40% of a team‚Äôs assists and 20% of a team‚Äôs points in a single season.\nWith the WNBA playoffs in full swing, and the Clark-less Fever making an inspired run, I am re-visiting that analysis.\nThis time, I have expanded the time frame to include that last 10 seasons of WNBA and NBA play as well as the WNBA regular season that just concluded. Data was pulled using the wehoop and hoopR R packages from the Sports Dataverse.\nAlso new this time is the interactive scatterplot below, created with the Observable Plot JavaScript library. There is a companion notebook on the Observable HQ platform, for those interested in creating something similar."
  },
  {
    "objectID": "posts/2025-09-21-draft/index.html#interactive-plot",
    "href": "posts/2025-09-21-draft/index.html#interactive-plot",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "Interactive Plot",
    "text": "Interactive Plot\n\n// transpose for usage with ojs\ndataOJS = transpose(data)\n\n\n\n\n\n\n\n// filter data based on radio button\nfilteredData = () =&gt; {\n  if (radios === \"All\") {\n    return dataOJS;\n} else {\n    return dataOJS.filter(d =&gt; d.League === radios)\n}\n}\n\n\n\n\n\n\n\nPlot.plot({\n  title: html`&lt;p style = \"margin-bottom: ${defaults.titleMarginBottom};  \n                            font-size:  ${defaults.titleFontSize};\n                            font-weight:  ${defaults.titleFontWeight};\n                            font-color: ${defaults.titleFontColor};\"&gt;Who contributed the most to their team's offensive output?&lt;/p&gt;`,\n  subtitle: html`&lt;p style = \"margin-bottom: ${defaults.subTitleMarginBottom}; \n                            font-size:  ${defaults.subTitleFontSize};\n                            margin-top: ${defaults.subtTitleMarginTop};\n                            font-color: ${defaults.subTitleFontColor};\"&gt;Point and Assist Shares by Player: WNBA & NBA (2015-2025)&lt;/p&gt;`,\n  inset: 8,\n  grid: true,\n  marginBottom: 70,\n\n  color: {\n    domain: [\"NBA\", \"WNBA\"],\n    range: [\"#003f66\", \"#FFB915\"],\n    legend: true\n  },\n  \n  x: {label: \"Share of Team Points (%)\",\n    tickFormat: d3.format(\".0%\"),\n     labelOffset: defaults.labelOffsetRegular},\n  y: {label: \"Share of Team Assists (%)\",\n    tickFormat: d3.format(\".0%\")},\n  caption: \"Data Sources: `wehoop` & `hoopR` R packages\",\n  marks: [\n    Plot.dot(filteredData(), {x: \"points_share\", \n                                 y: \"assist_share\", \n                                 stroke: \"League\", \n                                 channels: {\n                                  points: {\n                                    value: \"points_share\",\n                                    label: \"Points Share\"},\n                                  assists: {\n                                    value: \"assist_share\",\n                                    label: \"Assists Share\"\n                                  },\n                                  player: {\n                                    value: \"athlete_display_name\",\n                                    label: \"Player\"\n                                  },\n                                  team: {\n                                    value: \"team_display_name\",\n                                    label: \"Team\"\n                                  },\n                                   league: {\n                                     value: \"League\",\n                                     label: \"League\"},\n                                   season: {\n                                     value: \"season\",\n                                     label: \"Season\"\n                                   }\n                                  } ,\n                                  tip: {\n                                    format: {\n                                      player: true,\n                                      team: true,\n                                      points: (d) =&gt; d3.format(\".0%\")(d),\n                                      assists: (d) =&gt; d3.format(\".0%\")(d),\n                                      league: true,\n                                      season: (d) =&gt; d3.format(\".0f\")(d),\n                                      stroke: false,\n                                      y: false,\n                                      x: false\n                                  }\n                        }}),\n    Plot.ruleY([0.4],{strokeOpacity: 0.4}),\n    Plot.ruleX([0.2],{strokeOpacity: 0.4})\n  ]\n})\n\n\n\n\n\n\n\nviewof radios = Inputs.radio([\"WNBA\", \"NBA\", \"All\"], \n                             {label: \"Select League\", \n                              value: \"All\"})"
  },
  {
    "objectID": "posts/2025-09-21-draft/index.html#analysis-code",
    "href": "posts/2025-09-21-draft/index.html#analysis-code",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "Analysis Code",
    "text": "Analysis Code\nMy code is below for those interested in how to create something like this. Typically, I would just pull all required years of data in one API call. However, I realized mid-way through this project that the 2018 NBA team assist values were wrong (chronically low).\nSo, I pulled 2015:2017 and 2019:2025 from the load_nba_team_box function and then the 2018 NBA team values from the espn_nba_team_stats which seemed to be correct.\n\nWNBA Data\n\n# Load Packages\nlibrary(tidyverse)\nlibrary(wehoop)\nlibrary(hoopR)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(hrbrthemes)\nlibrary(scales)\n\n\n# All WNBA Seasons Data\n\nhist_wnba_player_box &lt;- wehoop::load_wnba_player_box(seasons = 2015:2025)\nhist_wnba_team_box &lt;- wehoop::load_wnba_team_box(seasons = 2015:2025)\n\n# Clean data: remove All-Star games' data and only use regular season data\n\nall_star_teams &lt;- c(\n  \"EAST\",\n  \"WEST\",\n  \"Team Parker\",\n  \"Team Delle Donne\",\n  \"Team Wilson\",\n  \"Team Usa\",\n  \"Team WNBA\",\n  \"Team Stewart\",\n  \"Team USA\",\n  \"TEAM COLLIER\",\n  \"TEAM CLARK\"\n)\n\nhist_wnba_player_box &lt;- hist_wnba_player_box %&gt;%\n  filter(\n    !team_display_name %in% all_star_teams,\n    season_type == 2\n  )\n\nhist_wnba_team_box &lt;- hist_wnba_team_box %&gt;%\n  filter(\n    !team_display_name %in% all_star_teams,\n    season_type == 2\n  )\n\n# Calculate total points and assists in season\nhist_wnba_pts_assists &lt;- hist_wnba_player_box %&gt;%\n  filter(did_not_play == FALSE) %&gt;%\n  group_by(season, athlete_id, athlete_display_name, team_id) %&gt;%\n  summarize(total_points = sum(points),\n            total_assists = sum(assists)) %&gt;%\n  arrange(desc(total_points)) \n\n\nhist_wnba_team_pts_assists &lt;- hist_wnba_team_box %&gt;%\n  group_by(season, team_id, team_display_name) %&gt;%\n  summarize(\n    total_assists = sum(assists),\n    total_points = sum(team_score)\n  ) %&gt;%\n  arrange(desc(total_points))\n\n\n# Join historical team and player data together\nhist_player_and_team &lt;- merge(x = hist_wnba_pts_assists,\n                              y = hist_wnba_team_pts_assists,\n                              by.x = c(\"season\", \"team_id\"),\n                              by.y = c(\"season\",\"team_id\"))\n\n# Calculate share of team points and assists\nhist_player_and_team &lt;- hist_player_and_team %&gt;%\n  rename(\n    team_assists = total_assists.y,\n    team_points = total_points.y\n  ) %&gt;%\n  mutate(\n    assist_share = total_assists.x/team_assists,\n    points_share = total_points.x/team_points,\n    assist_points_share = assist_share + points_share\n  )\n\n\n\nNBA Data\n\n# Load NBA data for comparison\nhist_nba_player_box &lt;- load_nba_player_box(seasons = c(2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025))\nhist_nba_team_box &lt;- load_nba_team_box(seasons = c(2015, 2016, 2017, 2019, 2020, 2021, 2022, 2023, 2024, 2025))\n\n# Clean data: remove All-Star games' data and only use regular season data\n\nnba_all_star_teams &lt;- c(\n  \"Eastern Conf All-Stars\",\n  \"Western Conf All-Stars\",\n  \"Team LeBron\",\n  \"Team Stephen\",\n  \"World\",\n  \"USA\",\n  \"Team Giannis\",\n  \"Leb\",\n  \"Usa\",\n  \"Team Durant\",\n  \"Team Chuck\",\n  \"Team Candace\",\n  \"Team Shaq\",\n  \"Team Kenny\"\n)\n\n\nhist_nba_player_box &lt;- hist_nba_player_box %&gt;%\n  filter(\n    !team_display_name %in% nba_all_star_teams,\n    season_type == 2\n  )\n\nhist_nba_team_box &lt;- hist_nba_team_box %&gt;%\n  filter(\n    !team_display_name %in% nba_all_star_teams,\n    season_type == 2\n  )\n\n\n# Calculate total points and assists in season\nhist_nba_pts_assists &lt;- hist_nba_player_box %&gt;%\n  filter(did_not_play == FALSE) %&gt;%\n  group_by(season, athlete_id, athlete_display_name, team_id) %&gt;%\n  summarize(total_points = sum(points),\n            total_assists = sum(assists)) %&gt;%\n  arrange(desc(total_points)) \n\n\nhist_nba_team_pts_assists &lt;- hist_nba_team_box %&gt;%\n  group_by(season, team_id, team_display_name) %&gt;%\n  summarize(\n    total_assists = sum(assists),\n    total_points = sum(team_score)\n  ) %&gt;%\n  arrange(desc(total_points))\n\n########\n# Clean data: pull in 2018 totals (incorrect from other data source)\n## Function wrapper for one team\nget_team_stats &lt;- function(team_id) {\n  espn_nba_team_stats(\n    team_id = team_id,\n    year = 2018,\n    season_type = \"regular\",\n    total = FALSE\n  )\n}\n\n## Vector of team ids (1 to 30)\nteam_ids &lt;- 1:30\n\n## Run through all and row-bind\nteam_stats_2018 &lt;- map_dfr(team_ids, get_team_stats, .id = \"team_id\")\n\n## pull out only stats needed\nespn_stats_2018 &lt;- team_stats_2018 %&gt;%\n  mutate(season = \"2018\") %&gt;%\n  select(season, team_id, team_display_name, offensive_assists, offensive_points)\n\n### make columns the same type and name\nespn_stats_2018[c(\"season\", \"team_id\", \"offensive_assists\", \"offensive_points\")] &lt;- lapply(espn_stats_2018[c(\"season\", \"team_id\", \"offensive_assists\", \"offensive_points\")], as.integer)\n\nespn_stats_2018 &lt;- espn_stats_2018 %&gt;%\n  rename(\n    total_points = offensive_points,\n    total_assists = offensive_assists\n  )\n\n## row bind 2018 team espn stats with bref stats\nhist_nba_team_pts_assists &lt;- rbind(hist_nba_team_pts_assists, espn_stats_2018)\n\n############\n\n# Join team and player data\nhist_nba_player_and_team &lt;- merge(x = hist_nba_pts_assists,\n                                  y = hist_nba_team_pts_assists,\n                                  by.x = c(\"season\", \"team_id\"),\n                                  by.y = c(\"season\",\"team_id\"))\n\n\n\nCombine leagues data and calculate assist and point shares\n\n# Calculate nba share of team points and assists\nhist_nba_player_and_team &lt;- hist_nba_player_and_team %&gt;%\n  rename(\n    team_assists = total_assists.y,\n    team_points = total_points.y\n  ) %&gt;%\n  mutate(\n    assist_share = total_assists.x/team_assists,\n    points_share = total_points.x/team_points,\n    assist_points_share = assist_share + points_share\n  )\n\n# Add \"League\" column\nhist_player_and_team &lt;- hist_player_and_team %&gt;%\n  mutate(\n    League = \"WNBA\"\n  )\n\nhist_nba_player_and_team &lt;- hist_nba_player_and_team %&gt;%\n  mutate(\n    League = \"NBA\"\n  )\n\n# Union WNBA and NBA data together\nnba_wnba_combined &lt;- rbind(hist_player_and_team, hist_nba_player_and_team)\n\n\ndefaults = ({\n  // fonts\n    fontSize: \"14px\",\n    fontFamily: \"Calibri\",\n    fontColor: \"#333\",\n  // margins around plot\n    marginTop: 15,\n    marginBottomRegular: 60,\n    marginBottomLarge: 100,\n  // labels\n    labelOffsetRegular: 40,\n    labelOffsetLarge: 85,\n  // title and subtitle\n    titleMarginBottom: 5,\n    titleFontSize: \"24px\",\n    titleFontWeight: \"bold\",\n    titleFontColor: \"#333\",\n    titleMarginBottom: 0,\n    subTitleMarginBottom: 15,\n    subtTitleMarginTop: 0,\n    subTitleFontSize: \"18px\",\n    subTitleFontColor: \"#333\",\n  // x axis\n    strokeOpacity: 0.25\n});"
  },
  {
    "objectID": "posts/2025-09-21-draft/index.html#conculsions",
    "href": "posts/2025-09-21-draft/index.html#conculsions",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "Conculsion(s)",
    "text": "Conculsion(s)\nThe only players to achieve 40-20 seasons since 2015 are (2017 was wild!):\n\nRussell Westbrook (2017): 49% assist share | 29% points share\nRussell Westbrook (2018): 47% assist share | 23% points share\nJames Harden (2017): 44% assist share | 25% points share\nRussell Westbrook (2016): 44% assist share | 21% points share\nCaitlin Clark (2024): 41% assist share | 23% points share\nJohn Wall (2017): 42% assist share | 42% points share\n\nClark is the only rookie and only WNBA player on this list. All of these players‚Äô associated teams made the playoffs, but none won the title. It would be interesting to see if a single player dominating a team‚Äôs offensive output has a positive or negative affect on their success‚Äìmaybe a topic for a future post?\nStill, it‚Äôs a fun stat and a truly remarkable feat for a rookie season. As a Fever fan, let‚Äôs hope she can get back on the court next season and keep breaking records."
  },
  {
    "objectID": "posts/2025-09-24-revisiting-clarks-2024-season/index.html",
    "href": "posts/2025-09-24-revisiting-clarks-2024-season/index.html",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "",
    "text": "Last year, I wrote that Caitlin Clark‚Äôs offensive contributions in her 2024 rookie season for the Indiana Fever was unmatched among both WNBA and NBA players since at least 2019. She was the only player in either league over this time span to contribute 40% of a team‚Äôs assists and 20% of a team‚Äôs points in a single season.\nWith the WNBA playoffs in full swing, and the Clark-less Fever making an inspired run, I am re-visiting that analysis.\nThis time, I have expanded the time frame to include that last 10 seasons of WNBA and NBA play as well as the WNBA regular season that just concluded. Data was pulled using the wehoop and hoopR R packages from the Sports Dataverse.\nAlso new this time is the interactive scatterplot below, created with the Observable Plot JavaScript library. There is a companion notebook on the Observable HQ platform, for those interested in creating something similar."
  },
  {
    "objectID": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#introduction",
    "href": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#introduction",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "",
    "text": "Last year, I wrote that Caitlin Clark‚Äôs offensive contributions in her 2024 rookie season for the Indiana Fever was unmatched among both WNBA and NBA players since at least 2019. She was the only player in either league over this time span to contribute 40% of a team‚Äôs assists and 20% of a team‚Äôs points in a single season.\nWith the WNBA playoffs in full swing, and the Clark-less Fever making an inspired run, I am re-visiting that analysis.\nThis time, I have expanded the time frame to include that last 10 seasons of WNBA and NBA play as well as the WNBA regular season that just concluded. Data was pulled using the wehoop and hoopR R packages from the Sports Dataverse.\nAlso new this time is the interactive scatterplot below, created with the Observable Plot JavaScript library. There is a companion notebook on the Observable HQ platform, for those interested in creating something similar."
  },
  {
    "objectID": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#interactive-plot",
    "href": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#interactive-plot",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "Interactive Plot",
    "text": "Interactive Plot\n\n// transpose for usage with ojs\ndataOJS = transpose(data)\n\n\n\n\n\n\n\n// filter data based on radio button\nfilteredData = () =&gt; {\n  if (radios === \"All\") {\n    return dataOJS;\n} else {\n    return dataOJS.filter(d =&gt; d.League === radios)\n}\n}\n\n\n\n\n\n\n\nPlot.plot({\n  title: html`&lt;p style = \"margin-bottom: ${defaults.titleMarginBottom};  \n                            font-size:  ${defaults.titleFontSize};\n                            font-weight:  ${defaults.titleFontWeight};\n                            font-color: ${defaults.titleFontColor};\"&gt;Who contributed the most to their team's offensive output?&lt;/p&gt;`,\n  subtitle: html`&lt;p style = \"margin-bottom: ${defaults.subTitleMarginBottom}; \n                            font-size:  ${defaults.subTitleFontSize};\n                            margin-top: ${defaults.subtTitleMarginTop};\n                            font-color: ${defaults.subTitleFontColor};\"&gt;Point and Assist Shares by Player: WNBA & NBA (2015-2025)&lt;/p&gt;`,\n  inset: 8,\n  grid: true,\n  marginBottom: 70,\n\n  color: {\n    domain: [\"NBA\", \"WNBA\"],\n    range: [\"#003f66\", \"#FFB915\"],\n    legend: true\n  },\n  \n  x: {label: \"Share of Team Points (%)\",\n    tickFormat: d3.format(\".0%\"),\n     labelOffset: defaults.labelOffsetRegular},\n  y: {label: \"Share of Team Assists (%)\",\n    tickFormat: d3.format(\".0%\")},\n  caption: \"Data Sources: `wehoop` & `hoopR` R packages\",\n  marks: [\n    Plot.dot(filteredData(), {x: \"points_share\", \n                                 y: \"assist_share\", \n                                 stroke: \"League\", \n                                 channels: {\n                                  points: {\n                                    value: \"points_share\",\n                                    label: \"Points Share\"},\n                                  assists: {\n                                    value: \"assist_share\",\n                                    label: \"Assists Share\"\n                                  },\n                                  player: {\n                                    value: \"athlete_display_name\",\n                                    label: \"Player\"\n                                  },\n                                  team: {\n                                    value: \"team_display_name\",\n                                    label: \"Team\"\n                                  },\n                                   league: {\n                                     value: \"League\",\n                                     label: \"League\"},\n                                   season: {\n                                     value: \"season\",\n                                     label: \"Season\"\n                                   }\n                                  } ,\n                                  tip: {\n                                    format: {\n                                      player: true,\n                                      team: true,\n                                      points: (d) =&gt; d3.format(\".0%\")(d),\n                                      assists: (d) =&gt; d3.format(\".0%\")(d),\n                                      league: true,\n                                      season: (d) =&gt; d3.format(\".0f\")(d),\n                                      stroke: false,\n                                      y: false,\n                                      x: false\n                                  }\n                        }}),\n    Plot.ruleY([0.4],{strokeOpacity: 0.4}),\n    Plot.ruleX([0.2],{strokeOpacity: 0.4})\n  ]\n})\n\n\n\n\n\n\n\nviewof radios = Inputs.radio([\"WNBA\", \"NBA\", \"All\"], \n                             {label: \"Select League\", \n                              value: \"All\"})"
  },
  {
    "objectID": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#conculsions",
    "href": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#conculsions",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "Conculsion(s)",
    "text": "Conculsion(s)\nThe only players to achieve 40-20 seasons since 2015 are (2017 was wild!):\n\nRussell Westbrook (2017): 49% assist share | 29% points share\nRussell Westbrook (2018): 47% assist share | 23% points share\nJames Harden (2017): 44% assist share | 25% points share\nRussell Westbrook (2016): 44% assist share | 21% points share\nCaitlin Clark (2024): 41% assist share | 23% points share\nJohn Wall (2017): 42% assist share | 42% points share\n\nClark is the only rookie and only WNBA player on this list. All of these players‚Äô associated teams made the playoffs, but none won the title. It would be interesting to see if a single player dominating a team‚Äôs offensive output has a positive or negative affect on their success‚Äìmaybe a topic for a future post?\nStill, it‚Äôs a fun stat and a truly remarkable feat for a rookie season. As a Fever fan, let‚Äôs hope she can get back on the court next season and keep breaking records."
  },
  {
    "objectID": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#analysis-code",
    "href": "posts/2025-09-24-revisiting-clarks-2024-season/index.html#analysis-code",
    "title": "Update: Clark‚Äôs 2024 season still stands out",
    "section": "Analysis Code",
    "text": "Analysis Code\nMy code is below for those interested in how to create something like this. Typically, I would just pull all required years of data in one API call. However, I realized mid-way through this project that the 2018 NBA team assist values were wrong (chronically low).\nSo, I pulled 2015:2017 and 2019:2025 from the load_nba_team_box function and then the 2018 NBA team values from the espn_nba_team_stats which seemed to be correct. I opened a GitHub issue for this and may take a look at attempting to fix it so others don‚Äôt run into the same problem.\n\nWNBA Data\n\n# Load Packages\nlibrary(tidyverse)\nlibrary(wehoop)\nlibrary(hoopR)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(hrbrthemes)\nlibrary(scales)\n\n\n# All WNBA Seasons Data\n\nhist_wnba_player_box &lt;- wehoop::load_wnba_player_box(seasons = 2015:2025)\nhist_wnba_team_box &lt;- wehoop::load_wnba_team_box(seasons = 2015:2025)\n\n# Clean data: remove All-Star games' data and only use regular season data\n\nall_star_teams &lt;- c(\n  \"EAST\",\n  \"WEST\",\n  \"Team Parker\",\n  \"Team Delle Donne\",\n  \"Team Wilson\",\n  \"Team Usa\",\n  \"Team WNBA\",\n  \"Team Stewart\",\n  \"Team USA\",\n  \"TEAM COLLIER\",\n  \"TEAM CLARK\"\n)\n\nhist_wnba_player_box &lt;- hist_wnba_player_box %&gt;%\n  filter(\n    !team_display_name %in% all_star_teams,\n    season_type == 2\n  )\n\nhist_wnba_team_box &lt;- hist_wnba_team_box %&gt;%\n  filter(\n    !team_display_name %in% all_star_teams,\n    season_type == 2\n  )\n\n# Calculate total points and assists in season\nhist_wnba_pts_assists &lt;- hist_wnba_player_box %&gt;%\n  filter(did_not_play == FALSE) %&gt;%\n  group_by(season, athlete_id, athlete_display_name, team_id) %&gt;%\n  summarize(total_points = sum(points),\n            total_assists = sum(assists)) %&gt;%\n  arrange(desc(total_points)) \n\n\nhist_wnba_team_pts_assists &lt;- hist_wnba_team_box %&gt;%\n  group_by(season, team_id, team_display_name) %&gt;%\n  summarize(\n    total_assists = sum(assists),\n    total_points = sum(team_score)\n  ) %&gt;%\n  arrange(desc(total_points))\n\n\n# Join historical team and player data together\nhist_player_and_team &lt;- merge(x = hist_wnba_pts_assists,\n                              y = hist_wnba_team_pts_assists,\n                              by.x = c(\"season\", \"team_id\"),\n                              by.y = c(\"season\",\"team_id\"))\n\n# Calculate share of team points and assists\nhist_player_and_team &lt;- hist_player_and_team %&gt;%\n  rename(\n    team_assists = total_assists.y,\n    team_points = total_points.y\n  ) %&gt;%\n  mutate(\n    assist_share = total_assists.x/team_assists,\n    points_share = total_points.x/team_points,\n    assist_points_share = assist_share + points_share\n  )\n\n\n\nNBA Data\n\n# Load NBA data for comparison\nhist_nba_player_box &lt;- load_nba_player_box(seasons = c(2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025))\nhist_nba_team_box &lt;- load_nba_team_box(seasons = c(2015, 2016, 2017, 2019, 2020, 2021, 2022, 2023, 2024, 2025))\n\n# Clean data: remove All-Star games' data and only use regular season data\n\nnba_all_star_teams &lt;- c(\n  \"Eastern Conf All-Stars\",\n  \"Western Conf All-Stars\",\n  \"Team LeBron\",\n  \"Team Stephen\",\n  \"World\",\n  \"USA\",\n  \"Team Giannis\",\n  \"Leb\",\n  \"Usa\",\n  \"Team Durant\",\n  \"Team Chuck\",\n  \"Team Candace\",\n  \"Team Shaq\",\n  \"Team Kenny\"\n)\n\n\nhist_nba_player_box &lt;- hist_nba_player_box %&gt;%\n  filter(\n    !team_display_name %in% nba_all_star_teams,\n    season_type == 2\n  )\n\nhist_nba_team_box &lt;- hist_nba_team_box %&gt;%\n  filter(\n    !team_display_name %in% nba_all_star_teams,\n    season_type == 2\n  )\n\n\n# Calculate total points and assists in season\nhist_nba_pts_assists &lt;- hist_nba_player_box %&gt;%\n  filter(did_not_play == FALSE) %&gt;%\n  group_by(season, athlete_id, athlete_display_name, team_id) %&gt;%\n  summarize(total_points = sum(points),\n            total_assists = sum(assists)) %&gt;%\n  arrange(desc(total_points)) \n\n\nhist_nba_team_pts_assists &lt;- hist_nba_team_box %&gt;%\n  group_by(season, team_id, team_display_name) %&gt;%\n  summarize(\n    total_assists = sum(assists),\n    total_points = sum(team_score)\n  ) %&gt;%\n  arrange(desc(total_points))\n\n########\n# Clean data: pull in 2018 totals (incorrect from other data source)\n## Function wrapper for one team\nget_team_stats &lt;- function(team_id) {\n  espn_nba_team_stats(\n    team_id = team_id,\n    year = 2018,\n    season_type = \"regular\",\n    total = FALSE\n  )\n}\n\n## Vector of team ids (1 to 30)\nteam_ids &lt;- 1:30\n\n## Run through all and row-bind\nteam_stats_2018 &lt;- map_dfr(team_ids, get_team_stats, .id = \"team_id\")\n\n## pull out only stats needed\nespn_stats_2018 &lt;- team_stats_2018 %&gt;%\n  mutate(season = \"2018\") %&gt;%\n  select(season, team_id, team_display_name, offensive_assists, offensive_points)\n\n### make columns the same type and name\nespn_stats_2018[c(\"season\", \"team_id\", \"offensive_assists\", \"offensive_points\")] &lt;- lapply(espn_stats_2018[c(\"season\", \"team_id\", \"offensive_assists\", \"offensive_points\")], as.integer)\n\nespn_stats_2018 &lt;- espn_stats_2018 %&gt;%\n  rename(\n    total_points = offensive_points,\n    total_assists = offensive_assists\n  )\n\n## row bind 2018 team espn stats with bref stats\nhist_nba_team_pts_assists &lt;- rbind(hist_nba_team_pts_assists, espn_stats_2018)\n\n############\n\n# Join team and player data\nhist_nba_player_and_team &lt;- merge(x = hist_nba_pts_assists,\n                                  y = hist_nba_team_pts_assists,\n                                  by.x = c(\"season\", \"team_id\"),\n                                  by.y = c(\"season\",\"team_id\"))\n\n\n\nCombine leagues data and calculate assist and point shares\n\n# Calculate nba share of team points and assists\nhist_nba_player_and_team &lt;- hist_nba_player_and_team %&gt;%\n  rename(\n    team_assists = total_assists.y,\n    team_points = total_points.y\n  ) %&gt;%\n  mutate(\n    assist_share = total_assists.x/team_assists,\n    points_share = total_points.x/team_points,\n    assist_points_share = assist_share + points_share\n  )\n\n# Add \"League\" column\nhist_player_and_team &lt;- hist_player_and_team %&gt;%\n  mutate(\n    League = \"WNBA\"\n  )\n\nhist_nba_player_and_team &lt;- hist_nba_player_and_team %&gt;%\n  mutate(\n    League = \"NBA\"\n  )\n\n# Union WNBA and NBA data together\nnba_wnba_combined &lt;- rbind(hist_player_and_team, hist_nba_player_and_team)\n\n\ndefaults = ({\n  // fonts\n    fontSize: \"14px\",\n    fontFamily: \"Calibri\",\n    fontColor: \"#333\",\n  // margins around plot\n    marginTop: 15,\n    marginBottomRegular: 60,\n    marginBottomLarge: 100,\n  // labels\n    labelOffsetRegular: 40,\n    labelOffsetLarge: 85,\n  // title and subtitle\n    titleMarginBottom: 5,\n    titleFontSize: \"24px\",\n    titleFontWeight: \"bold\",\n    titleFontColor: \"#333\",\n    titleMarginBottom: 0,\n    subTitleMarginBottom: 15,\n    subtTitleMarginTop: 0,\n    subTitleFontSize: \"18px\",\n    subTitleFontColor: \"#333\",\n  // x axis\n    strokeOpacity: 0.25\n});"
  }
]